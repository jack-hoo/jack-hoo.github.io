{"meta":{"title":"Jack-Hoo","subtitle":"Jack's Home","description":"A blog of Jack-Hoo","author":"JackHoo","url":"http://blog.jackhoo.cn"},"pages":[{"title":"All categories","date":"2018-03-13T07:25:16.000Z","updated":"2018-03-13T08:32:31.995Z","comments":true,"path":"categories/index.html","permalink":"http://blog.jackhoo.cn/categories/index.html","excerpt":"","text":""},{"title":"All tags","date":"2018-03-13T07:25:16.000Z","updated":"2018-03-13T07:25:57.263Z","comments":true,"path":"tags/index.html","permalink":"http://blog.jackhoo.cn/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"归并排序","slug":"归并排序","date":"2018-04-01T07:48:00.000Z","updated":"2018-04-01T07:54:38.650Z","comments":true,"path":"2018/04/01/归并排序/","link":"","permalink":"http://blog.jackhoo.cn/2018/04/01/归并排序/","excerpt":"","text":"代码实现1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465/** * FileName: Client * Author: shugan * Date: 2018/4/1 15:50 * Description: */package MegerSort;import java.util.Arrays;/** * 〈〉 * * @author shugan * @create 2018/4/1 * @since 1.0.0 */public class Client &#123; public static void main(String[] args) &#123; Client client = new Client(); int[] arr = new int[]&#123;23, 34, 54, 2, 3, 11&#125;; client.sort(arr); System.out.println(Arrays.toString(arr)); &#125; public void sort(int[] arr) &#123; int[] temp = new int[arr.length];//在排序前，先建好一个长度等于原数组长度的临时数组，避免递归中频繁开辟空间 sort(arr, 0, arr.length - 1, temp); &#125; private void sort(int[] arr, int left, int right, int[] temp) &#123; if (left &lt; right) &#123; int mid = (left + right) / 2; sort(arr, left, mid, temp);//左边归并排序，使得左子序列有序 sort(arr, mid + 1, right, temp);//右边归并排序，使得右子序列有序 merge(arr, left, mid, right, temp);//将两个有序子数组合并操作 &#125; &#125; private void merge(int[] arr, int left, int mid, int right, int[] temp) &#123; int i = left;//左序列指针 int j = mid + 1;//右序列指针 int t = 0;//临时数组指针 while (i &lt;= mid &amp;&amp; j &lt;= right) &#123; if (arr[i] &lt;= arr[j]) &#123; temp[t++] = arr[i++]; &#125; else &#123; temp[t++] = arr[j++]; &#125; &#125; while (i &lt;= mid) &#123;//将左边剩余元素填充进temp中 temp[t++] = arr[i++]; &#125; while (j &lt;= right) &#123;//将右序列剩余元素填充进temp中 temp[t++] = arr[j++]; &#125; t = 0; //将temp中的元素全部拷贝到原数组中 while (left &lt;= right) &#123; arr[left++] = temp[t++]; &#125; &#125;&#125; 结论归并排序是稳定排序，它也是一种十分高效的排序，能利用完全二叉树特性的排序一般性能都不会太差。java中Arrays.sort()采用了一种名为TimSort的排序算法，就是归并排序的优化版本。每次合并操作的平均时间复杂度为O(n)，而完全二叉树的深度为|log2n|。总的平均时间复杂度为O(nlogn)。而且，归并排序的最好，最坏，平均时间复杂度均为O(nlogn)。","categories":[{"name":"算法","slug":"算法","permalink":"http://blog.jackhoo.cn/categories/算法/"}],"tags":[{"name":"排序算法","slug":"排序算法","permalink":"http://blog.jackhoo.cn/tags/排序算法/"}]},{"title":"JVM的分区管理","slug":"JVM的分区管理","date":"2018-03-30T04:59:00.000Z","updated":"2018-03-30T12:02:31.581Z","comments":true,"path":"2018/03/30/JVM的分区管理/","link":"","permalink":"http://blog.jackhoo.cn/2018/03/30/JVM的分区管理/","excerpt":"","text":"JVM分区用途:永久存储区(Permanent Space):永久存储区是JVM的驻留内存,用于存放JDK自身所携带的Class,Interface的元数据,应用服务器允许必须的Class,Interface的元数据和Java程序运行时需要的Class和Interface的元数据。被装载进此区域的数据是不会被垃圾回收器回收掉的,关闭JVM时,释放此区域所控制的内存。 堆空间(The Heap Space):是JAVA对象生死存亡的地区,JAVA对象的出生,成长,死亡都在这个区域完成。堆空间又分别按JAVA对象的创建和年龄特征分为养老区和新生区。 新生区(Young (New) generation space):新生区的作用包括JAVA对象的创建和从JAVA对象中筛选出能进入养老区的JAVA对象。 伊甸园(Eden space):JAVA对空间中的所有对象在此出生,该区的名字因此而得名。也即是说当你的JAVA程序运行时,需要创建新的对象,JVM将在该区为你创建一个指定的对象供程序使用。创建对象的依据即是永久存储区中的元数据。 幸存者0区(Survivor 0 space)和幸存者1区(Survivor1 space):当伊甸园的控件用完时,程序又需要创建对象;此时JVM的垃圾回收器将对伊甸园区进行垃圾回收,将伊甸园区中的不再被其他对象所引用的对象进行销毁工作。同时将伊甸园中的还有其他对象引用的对象移动到幸存者0区。幸存者0区就是用于存放伊甸园垃圾回收时所幸存下来的JAVA对象。当将伊甸园中的还有其他对象引用的对象移动到幸存者0区时,如果幸存者0区也没有空间来存放这些对象时,JVM的垃圾回收器将对幸存者0区进行垃圾回收处理,将幸存者0区中不在有其他对象引用的JAVA对象进行销毁,将幸存者0区中还有其他对象引用的对象移动到幸存者1区。幸存者1区的作用就是用于存放幸存者0区垃圾回收处理所幸存下来的JAVA对象。 养老区(Tenure (Old) generation space):用于保存从新生区筛选出来的JAVA对象。上面我们看了JVM的内存分区管理,现在我们来看JVM的垃圾回收工作是怎样运作的。首先当启动J2EE应用服务器时,JVM随之启动,并将JDK的类和接口,应用服务器运行时需要的类和接口以及J2EE应用的类和接口定义文件以及编译后的Class文件或JAR包中的Class文件装载到JVM的永久存储区。在伊甸园中创建JVM应用服务器运行时必须的JAVA对象,创建J2EE应用启动时必须创建的JAVA对象;J2EE应用启动完毕,可对外提供服务。JVM在伊甸园区根据用户的每次请求创建相应的JAVA对象,当伊甸园的空间不足以用来创建新JAVA对象的时候,JVM的垃圾回收器执行对伊甸园区的垃圾回收工作,销毁那些不再被其他对象引用的JAVA对象(如果该对象仅仅被一个没有其他对象引用的对象引用的话,此对象也被归为没有存在的必要,依此类推),并将那些被其他对象所引用的JAVA对象移动到幸存者0区。如果幸存者0区有足够控件存放则直接放到幸存者0区;如果幸存者0区没有足够空间存放,则JVM的垃圾回收器执行对幸存者0区的垃圾回收工作,销毁那些不再被其他对象引用的JAVA对象(如果该对象仅仅被一个没有其他对象引用的对象引用的话,此对象也被归为没有存在的必要,依此类推),并将那些被其他对象所引用的JAVA对象移动到幸存者1区。如果幸存者1区有足够控件存放则直接放到幸存者1区;如果幸存者0区没有足够空间存放,则JVM的垃圾回收器执行对幸存者0区的垃圾回收工作,销毁那些不再被其他对象引用的JAVA对象(如果该对象仅仅被一个没有其他对象引用的对象引用的话,此对象也被归为没有存在的必要,依此类推),并将那些被其他对象所引用的JAVA对象移动到养老区。如果养老区有足够控件存放则直接放到养老区;如果养老区没有足够空间存放,则JVM的垃圾回收器执行对养老区区的垃圾回收工作,销毁那些不再被其他对象引用的JAVA对象(如果该对象仅仅被一个没有其他对象引用的对象引用的话,此对象也被归为没有存在的必要,依此类推),并保留那些被其他对象所引用的JAVA对象。如果到最后养老区,幸存者1区,幸存者0区和伊甸园区都没有空间的话,则JVM会报告“JVM堆空间溢出(java.lang.OutOfMemoryError: Java heap space)”,也即是在堆空间没有空间来创建对象。这就是JVM的内存分区管理,相比不分区来说;一般情况下,垃圾回收的速度要快很多;因为在没有必要的时候不用扫描整片内存而节省了大量时间。","categories":[{"name":"JVM","slug":"JVM","permalink":"http://blog.jackhoo.cn/categories/JVM/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"http://blog.jackhoo.cn/tags/JVM/"}]},{"title":"实习总结","slug":"实习总结","date":"2018-03-29T12:29:00.000Z","updated":"2018-03-30T02:42:42.060Z","comments":true,"path":"2018/03/29/实习总结/","link":"","permalink":"http://blog.jackhoo.cn/2018/03/29/实习总结/","excerpt":"","text":"why I came从去年的12月份我作为一名实习生来到二维火，第一次来到规模中等以上的公司，感受到了互联网公司的氛围。从刚进入公司HR紫苏的热情接待，以及正式入职后工作上同事朋友的悉心帮助和耐心解答，让我觉得二维火整体氛围真的非常的棒。 what I did入职后，我开始慢慢接触公司的业务，尽管自己此前学到的知识技能大多与公司用到的技能相符，但是公司的规范流程还是需要我迅速适应。自己开始第一次接触dubbo,看到公司的soa服务达到1w+让我开了眼界，自己也开始着手学习dubbo,因为此前接触过SpringCloud，duboo上手起来也相对容易。此后接手的第一个任务就是对几个服务端应用做切面监控，并输出到日志，以便于线上对指定店铺发生的问题进行查询。这个简单的任务也让我开始了解和关注公司内部的业务流程，也让我系统的学习了Spring AOP切面的原理和使用。 入职后一个月我做了团队的第一次分享，分享的主题是Java规则引擎的使用,为了这次分享自己也做了些许功课，查找大量资料，分析规则引擎的使用场景，以及它的优点，以备后期我们在自己的项目使用好它。 此后也多次中途参与一些项目的一部分功能，帮助同事写一些简单的接口，处理一些业务逻辑，虽然简单，但是自己对业务更加的熟悉，在不懂的地方请教同事(特别是灯草,在此感谢)也能让自己更快速的融入业务。 自己参与的第一个完整项目应该是达达优化和蜂鸟的接入，从项目立项，各种评审，开发，测试，预发各个环节都亲自走一遍，自己开始熟悉了这个流程，期间虽然遇到了一些问题，被指派了2个bug，最后都积极解决了，通过这个项目让我知道了提测前自己需要做好单测尽量做代码review，少写bug。 可能在学校的学习习惯的原因，我每天都会给自己留一些时间去做一些总结，写一下博客，看一些流行的技术。因为自己住的离公司比较近，如果没有特别的事，我习惯下班后在公司待一段时间，也很感谢公司提供的资源，让我把公司当成了图书馆，也比较喜欢一个人研究问题到深夜，所以通常都是12点多跟着公司管理员一起离开。因为目前自身状态的原因，把时间大多数都放在学习知识技能上，很感谢公司给了自己一个学习和工作的环境。 除了工作，平时傍晚也会跟同事一起去打篮球运动锻炼身体，这也很符合自己的生活节奏。 总而言之，身边的同事朋友都非常可爱，作为新人我非常感激 ！！！ The difficutites I MetHow I resolved The difficutitiesWhat I have learnedMy FaultsI Excepted","categories":[{"name":"类目","slug":"类目","permalink":"http://blog.jackhoo.cn/categories/类目/"}],"tags":[{"name":"标签1","slug":"标签1","permalink":"http://blog.jackhoo.cn/tags/标签1/"},{"name":"标签2","slug":"标签2","permalink":"http://blog.jackhoo.cn/tags/标签2/"}]},{"title":"数据库事务4种隔离级别及7种传播行为","slug":"数据库事务4种隔离级别及7种传播行为 ","date":"2018-03-28T11:47:00.000Z","updated":"2018-03-28T13:03:10.329Z","comments":true,"path":"2018/03/28/数据库事务4种隔离级别及7种传播行为 /","link":"","permalink":"http://blog.jackhoo.cn/2018/03/28/数据库事务4种隔离级别及7种传播行为 /","excerpt":"","text":"第1级别：Read Uncommitted(读取未提交内容)(1)所有事务都可以看到其他未提交事务的执行结果(2)本隔离级别很少用于实际应用，因为它的性能也不比其他级别好多少(3)该级别引发的问题是——脏读(Dirty Read)：读取到了未提交的数据 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162631.首先，修改隔离级别 set tx_isolation=&apos;READ-UNCOMMITTED&apos;; select @@tx_isolation; +------------------+ | @@tx_isolation | +------------------+ | READ-UNCOMMITTED | +------------------+2.事务A：启动一个事务 start transaction; select * from tx; +------+------+ | id | num | +------+------+ | 1 | 1 | | 2 | 2 | | 3 | 3 | +------+------+3.事务B：也启动一个事务(那么两个事务交叉了) 在事务B中执行更新语句，且不提交 start transaction; update tx set num=10 where id=1; select * from tx; +------+------+ | id | num | +------+------+ | 1 | 10 | | 2 | 2 | | 3 | 3 | +------+------+4.事务A：那么这时候事务A能看到这个更新了的数据吗? select * from tx; +------+------+ | id | num | +------+------+ | 1 | 10 | ---&gt;可以看到！说明我们读到了事务B还没有提交的数据 | 2 | 2 | | 3 | 3 | +------+------+5.事务B：事务B回滚,仍然未提交 rollback; select * from tx; +------+------+ | id | num | +------+------+ | 1 | 1 | | 2 | 2 | | 3 | 3 | +------+------+6.事务A：在事务A里面看到的也是B没有提交的数据 select * from tx; +------+------+ | id | num | +------+------+ | 1 | 1 | ---&gt;脏读意味着我在这个事务中(A中)，事务B虽然没有提交，但它任何一条数据变化，我都可以看到！ | 2 | 2 | | 3 | 3 | +------+------+ 第2级别：Read Committed(读取提交内容)(1)这是大多数数据库系统的默认隔离级别（但不是MySQL默认的）(2)它满足了隔离的简单定义：一个事务只能看见已经提交事务所做的改变(3)这种隔离级别出现的问题是——不可重复读(Nonrepeatable Read)：不可重复读意味着我们在同一个事务中执行完全相同的select语句时可能看到不一样的结果。 导致这种情况的原因可能有：(1)有一个交叉的事务有新的commit，导致了数据的改变;(2)一个数据库被多个实例操作时,同一事务的其他实例在该实例处理其间可能会有新的commit 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455561. 首先修改隔离级别set tx_isolation='read-committed';select @@tx_isolation;+----------------+| @@tx_isolation |+----------------+| READ-COMMITTED |+----------------+2. 事务A：启动一个事务start transaction;select * from tx;+------+------+| id | num |+------+------+| 1 | 1 || 2 | 2 || 3 | 3 |+------+------+3.事务B：也启动一个事务(那么两个事务交叉了) 在这事务中更新数据，且未提交start transaction;update tx set num=10 where id=1;select * from tx;+------+------+| id | num |+------+------+| 1 | 10 || 2 | 2 || 3 | 3 |+------+------+4. 事务A：这个时候我们在事务A中能看到数据的变化吗?select * from tx; ---------------&gt;+------+------+ || id | num | |+------+------+ || 1 | 1 |---&gt;并不能看到！ || 2 | 2 | || 3 | 3 | |+------+------+ |——&gt;相同的select语句，结果却不一样 |5. 事务B：如果提交了事务B呢? |commit; | |事务A: |select * from tx; ---------------&gt;+------+------+| id | num |+------+------+| 1 | 10 |---&gt;因为事务B已经提交了，所以在A中我们看到了数据变化| 2 | 2 || 3 | 3 |+------+------+ 第3级别：Repeatable Read(可重读)(1)这是MySQL的默认事务隔离级别(2)它确保同一事务的多个实例在并发读取数据时，会看到同样的数据行(3)此级别可能出现的问题——幻读(Phantom Read)：当用户读取某一范围的数据行时，另一个事务又在该范围内插入了新行，当用户再读取该范围的数据行时，会发现有新的“幻影” 行(4)InnoDB和Falcon存储引擎通过多版本并发控制(MVCC，Multiversion Concurrency Control)机制解决了该问题 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354551. 首先，更改隔离级别set tx_isolation='repeatable-read';select @@tx_isolation;+-----------------+| @@tx_isolation |+-----------------+| REPEATABLE-READ |+-----------------+2. 事务A：启动一个事务start transaction;select * from tx;+------+------+| id | num |+------+------+| 1 | 1 || 2 | 2 || 3 | 3 |+------+------+3. 事务B：开启一个新事务(那么这两个事务交叉了) 在事务B中更新数据，并提交start transaction;update tx set num=10 where id=1;select * from tx;+------+------+| id | num |+------+------+| 1 | 10 || 2 | 2 || 3 | 3 |+------+------+commit;4. 事务A：这时候即使事务B已经提交了,但A能不能看到数据变化？select * from tx;+------+------+| id | num |+------+------+| 1 | 1 | ---&gt;还是看不到的！(这个级别2不一样，也说明级别3解决了不可重复读问题)| 2 | 2 || 3 | 3 |+------+------+5. 事务A：只有当事务A也提交了，它才能够看到数据变化commit;select * from tx;+------+------+| id | num |+------+------+| 1 | 10 || 2 | 2 || 3 | 3 |+------+------+ 第4级别：Serializable(可串行化)(1)这是最高的隔离级别(2)它通过强制事务排序，使之不可能相互冲突，从而解决幻读问题。简言之,它是在每个读的数据行上加上共享锁。(3)在这个级别，可能导致大量的超时现象和锁竞争 1234567891011121314151617181. 首先修改隔离界别set tx_isolation='serializable';select @@tx_isolation;+----------------+| @@tx_isolation |+----------------+| SERIALIZABLE |+----------------+2. 事务A：开启一个新事务start transaction;3. 事务B：在A没有commit之前，这个交叉事务是不能更改数据的start transaction;insert tx values('4','4');ERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transactionupdate tx set num=10 where id=1;ERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transaction 二、传播行为 PROPAGATION_REQUIRED：如果当前没有事务，就创建一个新事务，如果当前存在事务，就加入该事务，该设置是最常用的设置。 PROPAGATION_SUPPORTS：支持当前事务，如果当前存在事务，就加入该事务，如果当前不存在事务，就以非事务执行。‘ PROPAGATION_MANDATORY：支持当前事务，如果当前存在事务，就加入该事务，如果当前不存在事务，就抛出异常。 PROPAGATION_REQUIRES_NEW：创建新事务，无论当前存不存在事务，都创建新事务。 PROPAGATION_NOT_SUPPORTED：以非事务方式执行操作，如果当前存在事务，就把当前事务挂起。 PROPAGATION_NEVER：以非事务方式执行，如果当前存在事务，则抛出异常。 PROPAGATION_NESTED：如果当前存在事务，则在嵌套事务内执行。如果当前没有事务，则执行与PROPAGATION_REQUIRED类似的操作。","categories":[{"name":"数据库","slug":"数据库","permalink":"http://blog.jackhoo.cn/categories/数据库/"}],"tags":[{"name":"事物","slug":"事物","permalink":"http://blog.jackhoo.cn/tags/事物/"},{"name":"sql","slug":"sql","permalink":"http://blog.jackhoo.cn/tags/sql/"}]},{"title":"我的个人简历","slug":"resume","date":"2018-03-28T11:10:00.000Z","updated":"2018-04-01T04:10:54.954Z","comments":true,"path":"2018/03/28/resume/","link":"","permalink":"http://blog.jackhoo.cn/2018/03/28/resume/","excerpt":"","text":"个人信息 胡上杰/男/1995 本科/江西财经大学/软件工程 工作经验：1年 技术博客：http://blog.jackhoo.cn Github：https://github.com/jack-hoo 手机：15088730887 Email：979783618@qq.com 微信号：jackhube 期望职位：Java后端工程师 到岗时间：一个月内 期望薪资：税前月薪15k 期望城市：杭州、深圳、广州 技能清单以下为我常用的技能 语言：Java、Scala、JavaScript、HTML5 后端框架：SpringBoot、SpringMVC、Mybatis、Hibernate 前端框架：Vue、JQuery、Webpack 数据库：MySQL、Redis 中间件：RabbitMQ 服务治理：Dubbo、SpringCloud 服务器：Tomcat、Nginx 操作系统：Linux常用操作 版本控制：Git、Svn 云开发平台：第三方登录、第三方支付、云直播、即时通讯 工作经历杭州二维火科技(2017/10 - 2018/4)职位: 收银服务端Java实习生 工作职责: 负责二维火收银app后台日常维护，确保用户日常收银正常使用。 参与国家高铁扫码点餐项目，负责云收银与高铁车厢店铺对接和数据绑定。 参与二维火收银外卖第三方配送对接，负责提供后台接口，处理外卖接单派单消息模块 南昌市敏而教育科技(2016/09 - 2017/09)职位: 自主创业者 工作职责: 大三时期联合学校技术爱好者组建一支4人技术团队，担任小Leader。 2016年12月发起校园直播项目，负责项目架构设计，后端编码工作，2017年3月项目上线，在学校晚会首次直播，在线观看数达6000人。 2017年4月项目运行一段时间由于无直播牌照被迫下线。 2017年5月创办自动发卡交易平台，担任站长。 项目经验国家高铁扫码点餐项目(2017/11 - 2018/03)项目描述：高铁扫码点餐实现了旅客在座位上即可扫码点菜品并完成支付，服务员通过云收银app接收下单消息，并予以配送，最终完成点餐操作。 项目职责： 负责高铁百万级二维码的生成和维护。 负责高铁旅客扫码下单模块的后台接口。 参与二维火云收银后台数据与高铁车厢店铺数据的对接。 Java快速开发平台(2017/05 - 2017/09)项目职责：个人开源项目，主要结合SpringBoot+SpringMvc+Mybatis+Vue做的一套前后端分离，开箱即用，可拓展的快速开发平台。 项目描述：项目包含基本的RBAC的权限管理模块，这部分基于SpringSecurity。基于Quartz的任务调度模块，集成多种支付接口。包含主流的云存储配置模块，可快速接入第三方云存储。安全层面做了XSS脚本过滤，以及SQL防注入。包含了基础的代码生成器，可生成基础的CRUD操作，还可生成前端Vue组件，实现了前后端分离，前端工程化。大大提高了开发效率，该项目是自身实践后为开发方便快捷而为之。 校园直播平台(2016/09 - 2017/05)项目职责： 项目负责人，从项目发起到项目落地全程负责。 负责项目的架构设计，技术选型，开放平台的对接。 完成服务端主要代码的编写，以及前端部分代码工作。 推动项目落地实行，进行首次校园晚会直播。 项目描述： 背景:2016年直播盛行，当时目标想把直播做成校园的另一种媒体传播模式，让学生的目光从网络娱乐直播转向校园里有趣的新鲜事。 项目:作为带头人联合3名感兴趣的同学一起做准备工作，看各种直播方案，也发表过一些简单的直播解决方案，最终我们搭建了一套以SpringBoot+Mybatis+Mysql+Redis+Vue.js 的一套项目骨架，使用第三方服务商提供的直播云服务和即时通讯服务。完成了以H5为主的直播观看端，使用Vue搭建了直播管理后台。 成果：在项目正式上线，我们扛着摄像机进行了第一次晚会直播，借助学校的宣传，首次直播同时观看人数达到6000多人，用户可在直播间互动交流，打赏等。 开源项目项目 小型网络在线教学平台 小直播系统的搭建 SSMV快速开发平台 文章 动手打造自己的直播间 致谢感谢您花时间阅读我的简历，期待能有机会和您共事。","categories":[{"name":"简历","slug":"简历","permalink":"http://blog.jackhoo.cn/categories/简历/"}],"tags":[{"name":"简历","slug":"简历","permalink":"http://blog.jackhoo.cn/tags/简历/"}]},{"title":"Mybatis中#和$符的用途","slug":"Mybatis中#和$符的用途","date":"2018-03-28T11:10:00.000Z","updated":"2018-03-28T11:47:04.665Z","comments":true,"path":"2018/03/28/Mybatis中#和$符的用途/","link":"","permalink":"http://blog.jackhoo.cn/2018/03/28/Mybatis中#和$符的用途/","excerpt":"","text":"一、举例说明12345select * from user where name = &quot;dato&quot;; select * from user where name = #&#123;name&#125;; select * from user where name = $&#123;name&#125;; 一般情况下，我们都不会注意到这里面有什么不一样的地方。因为这些sql都可以达到我们的目的，去查询名字叫dato的用户。 二、区别动态 SQL 是 mybatis 的强大特性之一，也是它优于其他 ORM 框架的一个重要原因。mybatis 在对 sql 语句进行预编译之前，会对 sql 进行动态解析，解析为一个 BoundSql 对象，也是在此处对动态 SQL 进行处理的。在动态 SQL 解析阶段， #{ } 和 ${ } 会有不同的表现 select * from user where name = #{name}; #{} 在动态解析的时候， 会解析成一个参数标记符。就是解析之后的语句是： select * from user where name = ？; 那么我们使用 ${}的时候 select * from user where name = ${name};${}在动态解析的时候，会将我们传入的参数当做String字符串填充到我们的语句中，就会变成下面的语句 select * from user where name = “dato”;预编译之前的 SQL 语句已经不包含变量了，完全已经是常量数据了。相当于我们普通没有变量的sql了。 综上所得， ${ } 变量的替换阶段是在动态 SQL 解析阶段，而 #{ }变量的替换是在 DBMS 中。 这是 #{} 和 ${} 我们能看到的主要的区别，除此之外，还有以下区别： #方式能够很大程度防止sql注入。$方式无法防止Sql注入。$方式一般用于传入数据库对象，例如传入表名.一般能用#的就别用$.所以我们在使用mybatis的时候，尽量的使用#方式！！！这是大家要注意的地方","categories":[{"name":"细节","slug":"细节","permalink":"http://blog.jackhoo.cn/categories/细节/"}],"tags":[{"name":"mybatis","slug":"mybatis","permalink":"http://blog.jackhoo.cn/tags/mybatis/"}]},{"title":"vue组件中this指代的究竟是谁？","slug":"vue组件中this指代的究竟是谁？","date":"2018-03-24T16:28:00.000Z","updated":"2018-03-24T17:12:01.829Z","comments":true,"path":"2018/03/25/vue组件中this指代的究竟是谁？/","link":"","permalink":"http://blog.jackhoo.cn/2018/03/25/vue组件中this指代的究竟是谁？/","excerpt":"","text":"js中的thisthis 指的是当前对象，如果在全局范围内使用this，则指代当前页面window；如果在函数中使用this，则this指代什么是根据当前函数是在什么对象上调用。我们可以使用call和apply改变函数中this的具体指向。123console.log(this === window) // trueconsole.log(window.alert === this.alert) // trueconsole.log(this.parseInt(\"021\",10)) // 21 函数中的this是在运行时候决定的，而不是函数定义时。1234567891011121314function foo()&#123; console.log(this.fruit);&#125;// 定义一个全局变量，等同于window.fruit = \"banana\";var fruit = \"banana\";// 此时函数中的this指向window;foo(); // \"banana\"var o = &#123; fruit : \"apple\", foo : foo &#125;;// 此时函数中的this指向oo.foo(); // \"apple\" vue中的this因为在vue组件中经常要用this指向组件的数据域和方法，1234567methods: &#123; nextPage (page) &#123; this.params.page = page; this.get_goods_list(); &#125;, &#125; 这样做完全可以正确获取到数据，但是请看下面的请看1234567891011121314data ()&#123; return &#123; a:0 &#125;&#125;,methods:&#123; count()&#123; setInterval( function()&#123; this.a += a +1 &#125; ),3000 &#125;&#125; 这样就有问题了，会出现this.a未定义，原因就是在此时this指向的是window对象，而不是该组件在es6中用箭头函数就可以完全避免这种问题123456789101112data ()&#123; return &#123; a:0 &#125;&#125;,methods:&#123; count()&#123; setInterval(() =&gt;&#123; this.a += a +1 &#125;,3000) &#125;&#125;","categories":[{"name":"vue","slug":"vue","permalink":"http://blog.jackhoo.cn/categories/vue/"}],"tags":[{"name":"javaScript","slug":"javaScript","permalink":"http://blog.jackhoo.cn/tags/javaScript/"},{"name":"前端","slug":"前端","permalink":"http://blog.jackhoo.cn/tags/前端/"}]},{"title":"记Java8Lambda局部变量的使用","slug":"记Java8Lambda局部变量的使用","date":"2018-03-21T05:00:00.000Z","updated":"2018-03-26T05:08:21.833Z","comments":true,"path":"2018/03/21/记Java8Lambda局部变量的使用/","link":"","permalink":"http://blog.jackhoo.cn/2018/03/21/记Java8Lambda局部变量的使用/","excerpt":"","text":"问题Lamdba表达式中可以使用外层作用域中定义的变量，就像匿名内部类。如下：12int portNumber = 1337;Runnable r = () -&gt; System.out.println(portNumber); 但是Lambda对于变量有一些限制，Lamdba可以没有限制的使用实例变量和静态变量，但是局部变量必须显示声明为final或者事实上是final（即一个变量虽然没被final修饰，但是他在后面也没被修改）。举例：12345int portNumber = 1337;Runnable r = () -&gt; System.out.println(portNumber);// 编译错误，因为portNumber 变量被赋值2次。// Lambda表达式引用的局部变量必须是final或者事实上是finalportNumber = 31337; 为什么对局部变量的限制?首先，实例变量和局部变量背后的实现有一个关键的不同，实例变量存储在堆上，而局部变量保存在栈上。 这种限制存在的原因在于局部变量保存在栈上，并且隐式表示它们仅限于其所在线程。如果允许捕获可改变的局部变量，就会引发造成线程不安全的新的可能性，而这是我们不想看到的（实例变量可以，因为它们保存在堆中，而堆是在线程之间共享的）。","categories":[{"name":"java基础","slug":"java基础","permalink":"http://blog.jackhoo.cn/categories/java基础/"}],"tags":[{"name":"lambda","slug":"lambda","permalink":"http://blog.jackhoo.cn/tags/lambda/"},{"name":"java8","slug":"java8","permalink":"http://blog.jackhoo.cn/tags/java8/"}]},{"title":"彻底搞懂二叉树的三种遍历方式","slug":"彻底搞懂二叉树的三种遍历方式","date":"2018-03-15T03:20:00.000Z","updated":"2018-03-27T03:27:23.236Z","comments":true,"path":"2018/03/15/彻底搞懂二叉树的三种遍历方式/","link":"","permalink":"http://blog.jackhoo.cn/2018/03/15/彻底搞懂二叉树的三种遍历方式/","excerpt":"","text":"三种遍历方式 先序遍历：遍历顺序规则为【根左右】 中序遍历：遍历顺序规则为【左根右】 后序遍历：遍历顺序规则为【左右根】 先看一棵树图，网上找了一个图 先序遍历：ABCDEFGHK 中序遍历：BDCAEHGKF 后序遍历：DCBHKGFEA 以中序遍历为例： 中序遍历的规则是【左根右】，我们从root节点A看起； 此时A是根节点，遍历A的左子树； A的左子树存在，找到B，此时B看做根节点，遍历B的左子树； B的左子树不存在，返回B，根据【左根右】的遍历规则，记录B，遍历B的右子树； B的右子树存在，找到C，此时C看做根节点，遍历C的左子树； C的左子树存在，找到D，由于D是叶子节点，无左子树，记录D，无右子树，返回C，根据【左根右】的遍历规则，记录C，遍历C的右子树； C的右子树不存在，返回B，B的右子树遍历完，返回A； 至此，A的左子树遍历完毕，根据【左根右】的遍历规则，记录A，遍历A的右子树； A的右子树存在，找到E，此时E看做根节点，遍历E的左子树； E的左子树不存在，返回E，根据【左根右】的遍历规则，记录E，遍历E的右子树； E的右子树存在，找到F，此时F看做根节点，遍历F的左子树； F的左子树存在，找到G，此时G看做根节点，遍历G的左子树； G的左子树存在，找到H，由于H是叶子节点，无左子树，记录H，无右子树，返回G，根据【左根右】的遍历规则，记录G，遍历G的右子树； G的右子树存在，找到K，由于K是叶子节点，无左子树，记录K，无右子树，返回G，根据【左根右】的遍历规则，记录F，遍历F的右子树； F的右子树不存在，返回F，E的右子树遍历完毕，返回A； 至此，A的右子树也遍历完毕； 这样先序后序也很好理解了。再也不会忘了，后面再动手用Java写个实现","categories":[{"name":"算法","slug":"算法","permalink":"http://blog.jackhoo.cn/categories/算法/"}],"tags":[{"name":"二叉树","slug":"二叉树","permalink":"http://blog.jackhoo.cn/tags/二叉树/"}]},{"title":"人脸识别学习记录","slug":"人脸识别demo","date":"2018-03-01T08:48:32.000Z","updated":"2018-03-26T07:06:11.652Z","comments":true,"path":"2018/03/01/人脸识别demo/","link":"","permalink":"http://blog.jackhoo.cn/2018/03/01/人脸识别demo/","excerpt":"","text":"人脸识别核心概念人脸人脸（Face）在人脸识别技术中特指图像中发现的人脸，当对一张图片进行人脸检测时，会将检测到的人脸记录下来，包括人脸在图片中的位置，用一个系统标识face_token来表示。注意：对同一张图片进行多次人脸检测，对同一个人脸会得到不同的face_token。 人脸集合人脸集合（FaceSet）是用来存储检测到人脸的存储对象。一个FaceSet内face_token是不重复的。 人脸比对/人脸搜索计算机检测到图片中一个人脸之后，通过人脸判断人身份的过程被称为人脸比对/人脸搜索。 人脸比对指采集新的人脸，与一个已知身份用户的人脸进行比对，判断新的人脸是否属于该已知身份用户。人脸比对需要调用Compare API。 人脸搜索是指采集用户新的人脸，在多个已知身份用户的人脸集合中进行搜索，找出新的人脸属于哪一个已知身份用户。人脸搜索需要调用Search API 学习资源先看看opencv吧，因为最近项目用到图像识别，需要截图后识别出图片上的文字并入库 opencv能用来干什么 内置数据结构和输入/输出(In-build data structures and input/output) 关于OpenCV的好处之一就是它提供了许多内置的用于图像处理和计算机视觉相关操作的基础元素。如果你需要通过scratch写入某些内容，你将不得不定义一些东西，比如图像、点、角度等等，这些几乎是任何计算机视觉算法的基础。OpenCV提供了这些开箱即用的基础数据结构，它们都包含在core模块中。另外一个好处是，这些数据结构都已经针对速度和内存做了优化，因此，你不用担心实现细节。 imgcodecs模块用于处理读取和写入图像文件(image file)。 图像处理操作(Image processing operations) 构建图形用户界面(Build GUI) 视频分析(Video analysis) 3D重建(3D reconstruction) 特征提取(Feature extraction) 目标检测(Object detection) 机器学习(Machine learning) 计算摄影(Computational photography) 形状分析(Shape analysis) 光流算法(Optical flow algorithms) 人脸和目标识别(Face and object recognition) 表面匹配(Surface matching) 文本检测和识别(Text detection and recognition) 上一个人脸识别小demogithub源码地址欢迎体验","categories":[{"name":"人工智能","slug":"人工智能","permalink":"http://blog.jackhoo.cn/categories/人工智能/"}],"tags":[{"name":"人脸识别","slug":"人脸识别","permalink":"http://blog.jackhoo.cn/tags/人脸识别/"},{"name":"人工智能","slug":"人工智能","permalink":"http://blog.jackhoo.cn/tags/人工智能/"}]},{"title":"RequestContextHolder类解析","slug":"RequestContextHolder类解析","date":"2018-02-28T16:51:00.000Z","updated":"2018-03-24T17:11:49.552Z","comments":true,"path":"2018/03/01/RequestContextHolder类解析/","link":"","permalink":"http://blog.jackhoo.cn/2018/03/01/RequestContextHolder类解析/","excerpt":"","text":"为什么要用RequestContextHolder正常情况下，我们都会在controller层取获取HttpServletRequest，然后中request中获取各种请求参数，但是，假如我们要在service层获取request对象怎么办，直接硬塞给service是不是过于暴力，这时候我们就可以选择使用RequestContextHolder1HttpServletRequest request = ((ServletRequestAttributes) RequestContextHolder.getRequestAttributes()).getRequest(); 看到这一般都会想到几个问题: request和response怎么和当前请求挂钩? request和response等是什么时候设置进去的? 源码剖析12345private static final ThreadLocal&lt;RequestAttributes&gt; requestAttributesHolder =new NamedThreadLocal&lt;RequestAttributes&gt;(\"Request attributes\");//可被子线程继承的requestprivate static final ThreadLocal&lt;RequestAttributes&gt; inheritableRequestAttributesHolder =new NamedInheritableThreadLocal&lt;RequestAttributes&gt;(\"Request context\"); 再看getRequestAttributes()方法,相当于直接获取ThreadLocal里面的值,这样就保证了每一次获取到的Request是该请求的request. 1234567public static RequestAttributes getRequestAttributes() &#123; RequestAttributes attributes = requestAttributesHolder.get(); if (attributes == null) &#123; attributes = inheritableRequestAttributesHolder.get(); &#125; return attributes; &#125; request和response等是什么时候设置进去的?下面看类图 HttpServletBean 进行初始化工作 FrameworkServlet 初始化 WebApplicationContext,并提供service方法预处理请 DispatcherServlet 具体分发处理. 那么就可以在FrameworkServlet查看到该类重写了service(),doGet(),doPost()…等方法,这些实现里面都有一个预处理方法processRequest(request, response);,所以定位到了我们要找的位置 查看processRequest(request, response);的实现,具体可以分为三步: 获取上一个请求的参数 重新建立新的参数 设置到XXContextHolder 父类的service()处理请求 恢复request 发布事件 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657protected final void processRequest(HttpServletRequest request, HttpServletResponse response)throws ServletException, IOException &#123;long startTime = System.currentTimeMillis();Throwable failureCause = null;//获取上一个请求保存的LocaleContext LocaleContext previousLocaleContext = LocaleContextHolder.getLocaleContext();//建立新的LocaleContext LocaleContext localeContext = buildLocaleContext(request);//获取上一个请求保存的RequestAttributes RequestAttributes previousAttributes = RequestContextHolder.getRequestAttributes();//建立新的RequestAttributes ServletRequestAttributes requestAttributes = buildRequestAttributes(request, response, previousAttributes); WebAsyncManager asyncManager = WebAsyncUtils.getAsyncManager(request);asyncManager.registerCallableInterceptor(FrameworkServlet.class.getName(), new RequestBindingInterceptor());//具体设置的方法 initContextHolders(request, localeContext, requestAttributes);try &#123; doService(request, response); &#125;catch (ServletException ex) &#123;failureCause = ex;throw ex; &#125;catch (IOException ex) &#123; failureCause = ex; throw ex; &#125;catch (Throwable ex) &#123; failureCause = ex; throw new NestedServletException(\"Request processing failed\", ex); &#125;finally &#123;//恢复 resetContextHolders(request, previousLocaleContext, previousAttributes);if (requestAttributes != null) &#123;requestAttributes.requestCompleted(); &#125;if (logger.isDebugEnabled()) &#123;if (failureCause != null) &#123;this.logger.debug(\"Could not complete request\", failureCause); &#125;else &#123;if (asyncManager.isConcurrentHandlingStarted()) &#123; logger.debug(\"Leaving response open for concurrent processing\"); &#125;else &#123;this.logger.debug(\"Successfully completed request\"); &#125; &#125; &#125;//发布事件 publishRequestHandledEvent(request, response, startTime, failureCause); &#125;&#125; 再看initContextHolders(request, localeContext, requestAttributes)方法,把新的RequestAttributes设置进LocalThread,实际上保存的类型为ServletRequestAttributes,这也是为什么在使用的时候可以把RequestAttributes强转为ServletRequestAttributes. 123456789101112131415private void initContextHolders(HttpServletRequest request, LocaleContext localeContext, RequestAttributes requestAttributes) &#123;if (localeContext != null) &#123; LocaleContextHolder.setLocaleContext(localeContext, this.threadContextInheritable); &#125;if (requestAttributes != null) &#123; RequestContextHolder.setRequestAttributes(requestAttributes, this.threadContextInheritable); &#125;if (logger.isTraceEnabled()) &#123; logger.trace(\"Bound request context to thread: \" + request); &#125;&#125; 因此RequestContextHolder里面最终保存的为ServletRequestAttributes,这个类相比RequestAttributes方法是多了很多.","categories":[{"name":"SpringMVC","slug":"SpringMVC","permalink":"http://blog.jackhoo.cn/categories/SpringMVC/"}],"tags":[{"name":"源码解析","slug":"源码解析","permalink":"http://blog.jackhoo.cn/tags/源码解析/"},{"name":"Request","slug":"Request","permalink":"http://blog.jackhoo.cn/tags/Request/"}]},{"title":"Java并发编程中的原子性、有序性、可见性","slug":"Java并发编程中的原子性、有序性、可见性","date":"2018-02-27T06:46:00.000Z","updated":"2018-03-27T06:51:06.832Z","comments":true,"path":"2018/02/27/Java并发编程中的原子性、有序性、可见性/","link":"","permalink":"http://blog.jackhoo.cn/2018/02/27/Java并发编程中的原子性、有序性、可见性/","excerpt":"","text":"并发程序正确地执行，必须要保证原子性、可见性以及有序性。只要有一个没有被保证，就有可能会导致程序运行不正确。 概念原子性：一个操作或多个操作要么全部执行完成且执行过程不被中断，要么就不执行。 可见性：当多个线程同时访问同一个变量时，一个线程修改了这个变量的值，其他线程能够立即看得到修改的值。 有序性：程序执行的顺序按照代码的先后顺序执行。 对于单线程，在执行代码时jvm会进行指令重排序，处理器为了提高效率，可以对输入代码进行优化，它不保证程序中各个语句的执行先后顺序同代码中的顺序一致，但是它会保证保存最终执行结果和代码顺序执行的结果是一致的。 原子性在java中，对基本数据类型的变量的读取和赋值操作是原子性操作，即这些操作是不可被中断，要么执行，要么不执行。 X=10; //原子性（简单的读取、将数字赋值给变量） Y = x; //变量之间的相互赋值，不是原子操作 X++; //对变量进行计算操作 X = x+1; 语句2实际包括两个操作，它先要去读取x的值，再将y值写入，两个操作分开是原子性的。合在一起就不是原子性的。 语句3、4:x++ x=x+1包括3个操作：读取x的值，x+1，将x写入 注：可以通过 synchronized和Lock实现原子性。因为synchronized和Lock能够保证任一时刻只有一个线程访问该代码块。 可见性Java提供了volatile关键字保证可见性。 当一个共享变量被volatile修饰时，它会保证修改的值立即被其他的线程看到，即修改的值立即更新到主存中，当其他线程需要读取时，它会去内存中读取新值。 Synchronized和Lock也可以保证可见性，因为它们可以保证任一时刻只有一个线程能访问共享资源，并在其释放锁之前将修改的变量刷新到内存中 有序性在Java里面，可以通过volatile关键字来保证一定的“有序性”（具体原理在下一节讲述volatile关键字）。另外可以通过synchronized和Lock来保证有序性，很显然，synchronized和Lock保证每个时刻是有一个线程执行同步代码，相当于是让线程顺序执行同步代码，自然就保证了有序性。 Java内存模型每个线程都有自己的工作内存（类似于前面的高速缓存）。线程对变量的所有操作都必须在工作内存中进行，而不能直接对主存进行操作。并且每个线程不能访问其他线程的工作内存。 Java内存模型具备一些先天的“有序性”，即不需要通过任何手段就能够得到保证的有序性，这个通常也称为happens-before 原则。如果两个操作的执行次序无法从happens-before原则推导出来，那么它们就不能保证它们的有序性，虚拟机可以随意地对它们进行重排序。 指令重排序：java语言规范规定JVM线程内部维持顺序化语义。即只要程序的最终结果与它顺序化情况的结果相等，那么指令的执行顺序可以与代码顺序不一致，此过程叫指令的重排序。 指令重排序的意义：JVM能根据处理器特性（CPU多级缓存系统、多核处理器等）适当的对机器指令进行重排序，使机器指令能更符合CPU的执行特性，最大限度的发挥机器性能。 下面就来具体介绍下happens-before原则（先行发生原则）： 程序次序规则：一个线程内，按照代码顺序，书写在前面的操作先行发生于书写在后面的操作 锁定规则：一个unLock操作先行发生于后面对同一个锁额lock操作 volatile变量规则：对一个变量的写操作先行发生于后面对这个变量的读操作。如果一个线程先去写一个变量，然后一个线程去进行读取，那么写入操作肯定会先行发生于读操作。 传递规则：如果操作A先行发生于操作B，而操作B又先行发生于操作C，则可以得出操作A先行发生于操作C。 线程启动规则：Thread对象的start()方法先行发生于此线程的每个一个动作 线程中断规则：对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生 线程终结规则：线程中所有的操作都先行发生于线程的终止检测，我们可以通过Thread.join()方法结束、Thread.isAlive()的返回值手段检测到线程已经终止执行 对象终结规则：一个对象的初始化完成先行发生于他的finalize()方法的开始","categories":[{"name":"多线程","slug":"多线程","permalink":"http://blog.jackhoo.cn/categories/多线程/"}],"tags":[{"name":"并发编程","slug":"并发编程","permalink":"http://blog.jackhoo.cn/tags/并发编程/"},{"name":"线程安全","slug":"线程安全","permalink":"http://blog.jackhoo.cn/tags/线程安全/"}]},{"title":"ArrayList在for循环中使用remove方法移除元素带来的问题","slug":"ArrayList在for循环中使用remove方法移除元素带来的问题","date":"2018-01-29T06:22:00.000Z","updated":"2018-03-29T06:26:52.155Z","comments":true,"path":"2018/01/29/ArrayList在for循环中使用remove方法移除元素带来的问题/","link":"","permalink":"http://blog.jackhoo.cn/2018/01/29/ArrayList在for循环中使用remove方法移除元素带来的问题/","excerpt":"","text":"有时候我们需要在一个ArrayList的for循环中动态删除元素的需求,如下123456789101112131415161718192021222324252627List&lt;Integer&gt; list = new ArrayList&lt;Integer&gt;(); list.add(0); list.add(1); list.add(2); list.add(3); list.add(4); list.add(5); list.add(6); list.add(7); //正常循环 for (int i = 0; i &lt; list.size(); i++) &#123; System.out.println(\"i的值:\" + i + \" 对应的数字:\" + list.get(i)); &#125; System.out.println(\"没有remove前list的项:\"+list.size()); //边循环边删除 for (int i = 0; i &lt; list.size(); i++) &#123; System.out.println(\"i的值:\" + i + \" 对应的数字:\" + list.get(i)); if(list.get(i) == 3) list.remove(list.get(i));//删除list的第四项 &#125; System.out.println(\"remove后list的项:\"+list.size()); System.out.println(\"==========remove后的list==========\"); for (int i = 0; i &lt; list.size(); i++) &#123; System.out.println(\"i的值:\" + i + \" 对应的数字:\" + list.get(i)); &#125; 执行代码, 结果如下:1234567891011121314151617181920212223242526i的值:0 对应的数字:0i的值:1 对应的数字:1i的值:2 对应的数字:2i的值:3 对应的数字:3i的值:4 对应的数字:4i的值:5 对应的数字:5i的值:6 对应的数字:6i的值:7 对应的数字:7没有remove前list的项:8i的值:0 对应的数字:0i的值:1 对应的数字:1i的值:2 对应的数字:2i的值:3 对应的数字:3i的值:4 对应的数字:5i的值:5 对应的数字:6i的值:6 对应的数字:7remove后list的项:7==========remove后的list==========i的值:0 对应的数字:0i的值:1 对应的数字:1i的值:2 对应的数字:2i的值:3 对应的数字:4i的值:4 对应的数字:5i的值:5 对应的数字:6i的值:6 对应的数字:7 可以看到没有删除前, 我们的list的项和循环对应的数字都是正确的, 但是下面的循环在删除第4个元素后,第4,5,6个项对应的数字本应该是4,5,6, 但是这里却变成了5,6,7.原因是,我们删除第4项后,list的长度就变成7,而且,list会把第4项后面的值往前移一位, 也就是说,i=3时,list.get(i)=4,i=4时,list.get(i)=5,i=5时,list.get(i)=6,i=6时,list.get(i)=7.. 我们再说的形象一点, 就是本来有8层糕点,依次是0-7,竖起来,大的在上,小的在下,我们从下往上数,数到第5个的时候,吃掉这一层糕点,这时,上面三层分别往下移了一层 所以, 值为4的项我们根本没有循环到 那有什么方法可以实现remove呢, 有个笨方法,是新建一个tempList, 把要删除的项全部add进去,最后用list.removeAll(tempList)实现 . 但是这里我们有更好的方法, 就是倒序删除 还是上面的例子, 代码:123456789101112131415161718192021222324252627List&lt;Integer&gt; list = new ArrayList&lt;Integer&gt;();list.add(0);list.add(1);list.add(2);list.add(3);list.add(4);list.add(5);list.add(6);list.add(7);//正常循环for (int i = 0; i &lt; list.size(); i++) &#123; System.out.println(\"i的值:\" + i + \" 对应的数字:\" + list.get(i));&#125;System.out.println(\"没有remove前list的项:\"+list.size());//边循环边删除for (int i = list.size() -1 ; i &gt;= 0; i--) &#123; System.out.println(\"i的值 \" + i + \" 对应的数字 \" + list.get(i)); if(list.get(i) == 3) list.remove(list.get(i));&#125;System.out.println(\"remove后list的项:\"+list.size());System.out.println(\"==========remove后的list==========\");for (int i = 0; i &lt; list.size(); i++) &#123; System.out.println(\"i的值 \" + i + \" 对应的数字 \" + list.get(i));&#125; 执行代码,结果如下:1234567891011121314151617181920212223242526i的值:0 对应的数字:0i的值:1 对应的数字:1i的值:2 对应的数字:2i的值:3 对应的数字:3i的值:4 对应的数字:4i的值:5 对应的数字:5i的值:6 对应的数字:6i的值:7 对应的数字:7没有remove前list的项:8i的值 7 对应的数字 7i的值 6 对应的数字 6i的值 5 对应的数字 5i的值 4 对应的数字 4i的值 3 对应的数字 3i的值 2 对应的数字 2i的值 1 对应的数字 1i的值 0 对应的数字 0remove后list的项:7==========remove后的list==========i的值 0 对应的数字 0i的值 1 对应的数字 1i的值 2 对应的数字 2i的值 3 对应的数字 4i的值 4 对应的数字 5i的值 5 对应的数字 6i的值 6 对应的数字 7 我们可以看到变循环变删除,并不影响后面的元素,remove后的list也和第一次的结果是一样的 . 这是因为我们删除list元素,list的长度是会变小, 但是变化的只是比当前被删除元素的项大的项, 而我们这里使用倒序循环, 大的项, 我们已经执行过了, 所以不会影响.. 再用上面的比喻来说明,这次我们是从上往下数,数到第4个的时候,吃掉这一层糕点,这时,上面三层分别往下移了一层 , 但是这不影响我们之前数过的蛋糕,而且对下面的蛋糕也不影响, 这就是原理","categories":[{"name":"Java基础","slug":"Java基础","permalink":"http://blog.jackhoo.cn/categories/Java基础/"}],"tags":[{"name":"ArrayList","slug":"ArrayList","permalink":"http://blog.jackhoo.cn/tags/ArrayList/"}]},{"title":"Nginx配置代理后获取到的ip都是127.0.0.1解决办法","slug":"Nginx配置代理后获取到的ip都是127.0.0.1解决办法","date":"2018-01-24T16:14:00.000Z","updated":"2018-03-24T16:28:20.778Z","comments":true,"path":"2018/01/25/Nginx配置代理后获取到的ip都是127.0.0.1解决办法/","link":"","permalink":"http://blog.jackhoo.cn/2018/01/25/Nginx配置代理后获取到的ip都是127.0.0.1解决办法/","excerpt":"","text":"原因squid，varnish以及nginx等，在做反向代理的时候，因为要代替客户端去访问服务器，所以，当请求包经过反向代理后，在代理服务器这里这个IP数据包的IP包头做了修改，最终后端web服务器得到的数据包的头部的源IP地址是代理服务器的IP地址，这样一来，后端服务器的程序给予IP的统计功能就没有任何意义，所以在做代理或集群的时候必须解决这个问题， 办法123456789101112location / &#123; proxy_pass http://127.0.0.1:8083; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header REMOTE-HOST $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; &#125; nginx几个变量 remote_addr代表客户端的IP，但它的值不是由客户端提供的，而是服务端根据客户端的ip指定的，当你的浏览器访问某个网站时，假设中间没有任何代理，那么网站的web服务器（Nginx，Apache等）就会把remote_addr设为你的机器IP，如果你用了某个代理，那么你的浏览器会先访问这个代理，然后再由这个代理转发到网站，这样web服务器就会把remote_addr设为这台代理机器的IP,除非代理将你的IP附在请求header中一起转交给web服务器。 X-Forwarded-For（简称XFF） X-Forwarded-For 是一个 HTTP 扩展头部。HTTP/1.1（RFC 2616）协议并没有对它的定义，它最开始是由 Squid 这个缓存代理软件引入，用来表示 HTTP 请求端真实 IP。如今它已经成为事实上的标准，被各大 HTTP 代理、负载均衡等转发服务广泛使用，并被写入 RFC 7239（Forwarded HTTP Extension）标准之中。 XFF的格式为： X-Forwarded-For: client, proxy1, proxy2 XFF 的内容由「英文逗号 + 空格」隔开的多个部分组成，最开始的是离服务端最远的设备 IP，然后是每一级代理设备的 IP。（注意：如果未经严格处理，可以被伪造） 如果一个 HTTP 请求到达服务器之前，经过了三个代理 Proxy1、Proxy2、Proxy3，IP 分别为 IP1、IP2、IP3，用户真实 IP 为 IP0，那么按照 XFF 标准，服务端最终会收到以下信息： X-Forwarded-For: IP0, IP1, IP2 Proxy3 直连服务器，它会给 XFF 追加 IP2，表示它是在帮 Proxy2 转发请求。列表中并没有 IP3，IP3 可以在服务端通过 Remote Address 字段获得。我们知道 HTTP 连接基于 TCP 连接，HTTP 协议中没有 IP 的概念，Remote Address 来自 TCP 连接，表示与服务端建立 TCP 连接的设备 IP，在这个例子里就是 IP3。Remote Address 无法伪造，因为建立 TCP 连接需要三次握手，如果伪造了源 IP，无法建立 TCP 连接，更不会有后面的 HTTP 请求。但是在正常情况下，web服务器获取Remote Address只会获取到上一级的IP。 X-Real-IP 这又是一个自定义头部字段，通常被 HTTP 代理用来表示与它产生 TCP 连接的设备 IP，这个设备可能是其他代理，也可能是真正的请求端，这个要看经过代理的层级次数或是是否始终将真实IP一路传下来。（注意：如果未经严格处理，可以被伪造） 贴一段根据ip获取区域地址的代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239package com.miner.out.jielin_fast.common.utils;import com.miner.out.jielin_fast.controller.AuthController;import org.apache.commons.lang.StringUtils;import org.apache.commons.logging.LogFactory;import org.apache.log4j.Logger;import org.slf4j.LoggerFactory;import javax.servlet.http.HttpServletRequest;import java.io.*;import java.net.HttpURLConnection;import java.net.URL;public class AddressUtils &#123; /** * @param content * 请求的参数 格式为：name=xxx&amp;pwd=xxx * @param encoding * 服务器端请求编码。如GBK,UTF-8等 * @return * @throws UnsupportedEncodingException */ protected final static org.slf4j.Logger log = LoggerFactory.getLogger(AuthController.class); public static String getAddresses(String ip)&#123; try &#123; String urlStr =\"http://ip.taobao.com/service/getIpInfo.php\"; String returnStr = getResult(urlStr, ip); if (returnStr != null) &#123; // 处理返回的省市区信息 String[] temp = returnStr.split(\",\"); if (temp.length &lt; 3) &#123; return \"0\";// 无效IP，局域网测试 &#125; String region = (temp[5].split(\":\"))[1].replaceAll(\"\\\"\", \"\"); region = decodeUnicode(region);// 省份 String country = \"\"; String area = \"\"; // String region = \"\"; String city = \"\"; String county = \"\"; String isp = \"\"; for (int i = 0; i &lt; temp.length; i++) &#123; switch (i) &#123; case 1: country = (temp[i].split(\":\"))[2].replaceAll(\"\\\"\", \"\"); country = decodeUnicode(country);// 国家 break; case 3: area = (temp[i].split(\":\"))[1].replaceAll(\"\\\"\", \"\"); area = decodeUnicode(area);// 地区 break; case 5: region = (temp[i].split(\":\"))[1].replaceAll(\"\\\"\", \"\"); region = decodeUnicode(region);// 省份 break; case 7: city = (temp[i].split(\":\"))[1].replaceAll(\"\\\"\", \"\"); city = decodeUnicode(city);// 市区 break; case 9: county = (temp[i].split(\":\"))[1].replaceAll(\"\\\"\", \"\"); county = decodeUnicode(county);// 地区 break; case 11: isp = (temp[i].split(\":\"))[1].replaceAll(\"\\\"\", \"\"); isp = decodeUnicode(isp); // ISP公司 break; &#125; &#125; String address = region+city; if(StringUtils.isBlank(address))&#123; address = \"地球村\"; &#125; return address; &#125; &#125; catch (Exception e) &#123; log.error(\"获取ip错误\"+e); return null; &#125; return null; &#125; /** * @param urlStr * 请求的地址 * @param content * 请求的参数 格式为：name=xxx&amp;pwd=xxx * @param encoding * 服务器端请求编码。如GBK,UTF-8等 * @return */ private static String getResult(String urlStr, String ip) &#123; URL url = null; HttpURLConnection connection = null; try &#123; url = new URL(urlStr); connection = (HttpURLConnection) url.openConnection();// 新建连接实例 /** * 超时错误 由 2s改为5s */ connection.setConnectTimeout(5000);// 设置连接超时时间，单位毫秒 connection.setReadTimeout(5000);// 设置读取数据超时时间，单位毫秒 connection.setDoOutput(true);// 是否打开输出流 true|false connection.setDoInput(true);// 是否打开输入流true|false connection.setRequestMethod(\"POST\");// 提交方法POST|GET connection.setUseCaches(false);// 是否缓存true|false connection.connect();// 打开连接端口 DataOutputStream out = new DataOutputStream(connection.getOutputStream());// 打开输出流往对端服务器写数据 out.writeBytes(\"ip=\"+ip);// 写数据,也就是提交你的表单 name=xxx&amp;pwd=xxx out.flush();// 刷新 out.close();// 关闭输出流 BufferedReader reader = new BufferedReader(new InputStreamReader(connection.getInputStream(), \"utf-8\"));// 往对端写完数据对端服务器返回数据 // ,以BufferedReader流来读取 StringBuffer buffer = new StringBuffer(); String line = \"\"; while ((line = reader.readLine()) != null) &#123; buffer.append(line); &#125; reader.close(); return buffer.toString(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; finally &#123; if (connection != null) &#123; connection.disconnect();// 关闭连接 &#125; &#125; return null; &#125; /** * unicode 转换成 中文 * @param theString * @return */ public static String decodeUnicode(String theString) &#123; char aChar; int len = theString.length(); StringBuffer outBuffer = new StringBuffer(len); for (int x = 0; x &lt; len;) &#123; aChar = theString.charAt(x++); if (aChar == '\\\\') &#123; aChar = theString.charAt(x++); if (aChar == 'u') &#123; int value = 0; for (int i = 0; i &lt; 4; i++) &#123; aChar = theString.charAt(x++); switch (aChar) &#123; case '0': case '1': case '2': case '3': case '4': case '5': case '6': case '7': case '8': case '9': value = (value &lt;&lt; 4) + aChar - '0'; break; case 'a': case 'b': case 'c': case 'd': case 'e': case 'f': value = (value &lt;&lt; 4) + 10 + aChar - 'a'; break; case 'A': case 'B': case 'C': case 'D': case 'E': case 'F': value = (value &lt;&lt; 4) + 10 + aChar - 'A'; break; default: throw new IllegalArgumentException(\"Malformed encoding.\"); &#125; &#125; outBuffer.append((char) value); &#125; else &#123; if (aChar == 't') &#123; aChar = '\\t'; &#125; else if (aChar == 'r') &#123; aChar = '\\r'; &#125; else if (aChar == 'n') &#123; aChar = '\\n'; &#125; else if (aChar == 'f') &#123; aChar = '\\f'; &#125; outBuffer.append(aChar); &#125; &#125; else &#123; outBuffer.append(aChar); &#125; &#125; return outBuffer.toString(); &#125; /** * 获取IP地址 * @Author 科帮网 * @param request * @return String * @Date 2017年7月31日 * 更新日志 * 2017年7月31日 科帮网 首次创建 * */ public static String getIpAddr(HttpServletRequest request) &#123; String ip = request.getHeader(\"X-Real-IP\"); if(!StringUtils.isBlank(ip) &amp;&amp; !\"unknown\".equalsIgnoreCase(ip)) return ip; ip = request.getHeader(\"X-Forwarded-For\"); if(!StringUtils.isBlank(ip) &amp;&amp; !\"unknown\".equalsIgnoreCase(ip)) &#123; int index = ip.indexOf(','); if(index != -1) return ip.substring(0, index); else return ip; &#125; if(ip == null || ip.length() == 0 || \"unknown\".equalsIgnoreCase(ip)) ip = request.getHeader(\"Proxy-Client-IP\"); if(ip == null || ip.length() == 0 || \"unknown\".equalsIgnoreCase(ip)) ip = request.getHeader(\"WL-Proxy-Client-IP\"); if(ip == null || ip.length() == 0 || \"unknown\".equalsIgnoreCase(ip)) ip = request.getHeader(\"HTTP_CLIENT_IP\"); if(ip == null || ip.length() == 0 || \"unknown\".equalsIgnoreCase(ip)) ip = request.getHeader(\"HTTP_X_FORWARDED_FOR\"); if(ip == null || ip.length() == 0 || \"unknown\".equalsIgnoreCase(ip)) ip = request.getRemoteAddr(); return ip; &#125;&#125;","categories":[{"name":"nginx","slug":"nginx","permalink":"http://blog.jackhoo.cn/categories/nginx/"}],"tags":[{"name":"nginx","slug":"nginx","permalink":"http://blog.jackhoo.cn/tags/nginx/"}]},{"title":"Java常用String类小记","slug":"Java常用String类小记","date":"2017-11-06T12:45:00.000Z","updated":"2018-03-23T17:17:24.562Z","comments":true,"path":"2017/11/06/Java常用String类小记/","link":"","permalink":"http://blog.jackhoo.cn/2017/11/06/Java常用String类小记/","excerpt":"","text":"java.lang.String 概览 继承结构 Serializable CharSequence Comparable 字符集简介 重要域成员 重要方法 代码点及代码单元 比较 搜索 提取子串 创建全大写/全小写副本 一些体会 参考 概览String 类代表了字符串。所有类似于 &quot;abc&quot; 的字符串字面量都是该类的实例。 字符串是常量，从创建后就不可更改。需要修改的字符串可以使用 StringBuffer。因为 String 实例不可变，所以他们可以安全的共享。一些例子： 1234567891011String str = \"abc\";// 与上面一行代码效果相同char data[] = &#123;'a', 'b', 'c'&#125;;String str = new String(data);System.out.println(\"abc\");String cde = \"cde\";System.out.println(\"abc\" + cde);String c = \"abc\".substring(2,3);String d = cde.substring(1, 2); String 类也包含了一些对单个字符的操作、比较、搜索、提取子串、创建全大写/全小写副本的方法。 Java 语言为字符串连接操作符(+)添加了特殊支持。向左连接。 1234567891011121314151617// example 1\"The square root of 2 is \" + Math.sqrt(2) | v\"The square root of 2 is 1.4142135623730952\"// example 21 + 2 + \" fiddlers\" | v\"3 fiddlers\"// example 3\"fiddlers \" + 1 + 2 | v\"fiddlers 12\" String 使用 UTF-16 来编码（一个字符两个字节或四个字节）。拓展字符用 surrogate pairs 来表示，占用四个字节。（PS：该术语是编码领域的，可以参考之前写的一篇笔记: Unicode 学习笔记） String 也提供了一些处理代码点(Unicode code points)和代码单元(Unicode code units)的方法(PS:这两个也是编码领域术语，可以参考：Unicode 学习笔记)。 String 连接操作符的具体实现留给 Java 编译器来决定，只要编译器能够完全遵循 Java 语言规范即可。例如 javac 编译器可能用 StringBuffer、StringBuilder 或 java.lang.invoke.StringCOncatFactory 来实现。 继承结构 Serializable类通过实现 java.io.Serializable 接口来启用序列化能力。未实现该接口的类其状态将不会被序列化(抛出 NotSerializableException 异常)。该接口没有任何域或方法，只是表示可序列化的语义。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public static void serializableTest() throws IOException, ClassNotFoundException &#123; String outputfile = \"/Users/chen/Desktop/serializable\"; ST instance = new ST(); ObjectOutputStream outputStream = new ObjectOutputStream(new FileOutputStream(outputfile)); outputStream.writeObject(instance); outputStream.close(); ObjectInputStream inputStream = new ObjectInputStream(new FileInputStream(outputfile)); ST newInstance = (ST) inputStream.readObject(); inputStream.close(); System.out.println(newInstance); System.out.println(instance.equals(newInstance)); // true System.out.println(instance == newInstance); //false&#125;static class ST implements Serializable&#123; public int publicField = 1; protected int protectedField = 1; int defaultField = 1; private int privateField = 1; @Override public boolean equals(Object o) &#123; if (this == o) &#123; return true; &#125; if (o == null || getClass() != o.getClass()) &#123; return false; &#125; ST st = (ST) o; return publicField == st.publicField &amp;&amp; protectedField == st.protectedField &amp;&amp; defaultField == st.defaultField &amp;&amp; privateField == st.privateField; &#125; @Override public int hashCode() &#123; return Objects.hash(publicField, protectedField, defaultField, privateField); &#125; @Override public String toString() &#123; return \"ST&#123;\" + \"publicField=\" + publicField + \", protectedField=\" + protectedField + \", defaultField=\" + defaultField + \", privateField=\" + privateField + '&#125;'; &#125;&#125; 序列化的对象中引用的所有对象都必须实现了该接口，否则也会抛出 NotSerializableException 异常。 CharSequence一个 CharSequence 是一个只读的 char 序列。该接口为不同的实现提供了统一的只读访问。 该接口并没有重新定义 equals() &amp; hashCode() 方法，直接比较两个实现类的实例结果是未定义的。所以将 CharSequence 的实例作为 set 的元素或 map 的 key 是不合适的。 主要的实现类：CharBuffer, Segment, String, StringBuffer, StringBuilder String 中也实现了与 CharSequence 实例进行比较、拼接等操作的函数。 Comparable主要用于集合中元素排序，两个元素直接比较。 字符集简介String 类中用到了两种字符集 Latin1 &amp; UTF-16. Latin1 拓展了 ASCII 编码，但是也是用一个字节来表示，UTF-16 使用两个或四个字节表示一个字符。简要介绍请看：Unicode 学习笔记 12345678910111213141516171819202122232425/** 在构造一个 String 对象时，String 会尝试对传入的参数进行压缩。比如 String latin1 = new String(\"latin1\".toCharArray()); String utf16 = new String(\"使用 UTF-16 字符集\".toCharArray()); 入参是 char[]，java 中 char 是两个字节，byte 是一个字节，压缩后 latin1 的 value 字段是 6 个 byte，utf16 无法进行压缩，所以依旧是 26 个 byte。 下面是 java.lang.StringUTF16 中进行压缩的函数。 */ // compressedCopy char[] -&gt; byte[] @HotSpotIntrinsicCandidate public static int compress(char[] src, int srcOff, byte[] dst, int dstOff, int len) &#123; for (int i = 0; i &lt; len; i++) &#123; char c = src[srcOff]; if (c &gt; 0xFF) &#123; // 超出了 LATIN1 所能表示的范围，直接返回不再压缩 len = 0; break; &#125; dst[dstOff] = (byte)c; srcOff++; dstOff++; &#125; return len; &#125; 重要域成员 private final byte[] value; 用来存储字符串的字节序列。 private final byte coder; 用来暗示 value 中的字节数组的编码方式。有 LATIN1 &amp; UTF16 可选。 static final byte LATIN1 = 0; static final byte UTF16 = 1; private int hash; 缓存字符串哈希值。默认是 0. 在 首次调用 hashCode() 方法时计算并缓存。 static final boolean COMPACT_STRINGS; 用来决定 value 是否进行压缩，默认是 true（压缩）。如果是 false 的话那么总是使用 UTF16 来编码字符串的字节流。在 String 类中，该域使用静态初始化块进行初始化。 重要方法 TIPS：本来计划中有这部分的内容，但是读过源码理解了字符集的概念和 String 的处理方式以后感觉这部分就不需要再写了，有兴趣可以自己看。 代码点及代码单元比较搜索提取子串创建全大写/全小写副本一些体会理解 String 类最重要的不是会用 String 的 API，而是对字符集本身的理解，字符集是什么，它解决了什么问题，字符是怎么编码的等等，只有很好的理解了字符集才能很好的理解 String 的行为。 参考 java.lang.String 15.18.1. String Concatenation Operator + Serializable JAVA 对象序列化（一）——Serializable CharSequence ISO/IEC 8859-1","categories":[{"name":"Java基础","slug":"Java基础","permalink":"http://blog.jackhoo.cn/categories/Java基础/"}],"tags":[{"name":"java基础","slug":"java基础","permalink":"http://blog.jackhoo.cn/tags/java基础/"},{"name":"字符串拼接","slug":"字符串拼接","permalink":"http://blog.jackhoo.cn/tags/字符串拼接/"}]},{"title":"Effective-Java学习笔记","slug":"Effective-Java","date":"2017-11-01T15:45:00.000Z","updated":"2018-03-23T17:13:54.504Z","comments":true,"path":"2017/11/01/Effective-Java/","link":"","permalink":"http://blog.jackhoo.cn/2017/11/01/Effective-Java/","excerpt":"","text":"Effective Java 学习笔记 Effective Java 学习笔记 第三章 对所有方法都通用的方法 equals() hashCode() 第六章 枚举和注解 第七章 方法 第八章 通用程序设计 第三章 对所有方法都通用的方法equals()当类为值类（以类中保存的值来区别两个实例）时（枚举例外），需要重写 equals() 和 hashCode() 方法。 重写 equals() 需要遵守的约定： 非空。x != null 自反。x.equals(x) == true 对称。if(x.equals(y)) y.equals(x) 传递。if(x.equals(y) &amp;&amp; y.equals(z)) x.equals(z) 一致。 只要对象不变，每次调用必须能返回相同的结果。 Tips： 增加值组件时使用符合而不是继承。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162public class Point &#123; private final int x; private final int y; public Point(int x, int y) &#123; this.x = x; this.y = y; &#125; @Override public boolean equals(Object o) &#123; if (this == o) &#123; return true; &#125; if (o == null || !(o instanceof Point)) &#123; return false; &#125; Point point = (Point) o; return x == point.x &amp;&amp; y == point.y; &#125; @Override public int hashCode() &#123; int result = x; result = 31 * result + y; return result; &#125;&#125;public class ColorPoint &#123; private final Point point; private final Color color; public ColorPoint(Point point, Color color) &#123; this.point = point; this.color = color; &#125; @Override public boolean equals(Object o) &#123; if (this == o) &#123; return true; &#125; if (o == null || !(o instanceof ColorPoint)) &#123; return false; &#125; ColorPoint that = (ColorPoint) o; if (point != null ? !point.equals(that.point) : that.point != null) &#123; return false; &#125; return color != null ? color.equals(that.color) : that.color == null; &#125; @Override public int hashCode() &#123; int result = point != null ? point.hashCode() : 0; result = 31 * result + (color != null ? color.hashCode() : 0); return result; &#125;&#125; 对于 float 和 double 类型的值进行特殊处理 Float.compare(f1, f2) 域的比较顺序有可能会影响性能，所以应先比较最有可能不同的域及开销最低的域。 总是要覆盖 hashCode() 方法。 hashCode()约定： 在应用程序执行过程中，只要 equals() 方法未更改，同一个对象调用 hashCode() 返回结果应该一致。 if(x.equals(y)) x.hashCode() == y.hashCode(); 实现约定: 将一个非 0 常量赋给 result。 计算关键域的 hashCode boolean –&gt; field ? 1 : 0; Byte | char | short | int –&gt; (int)field long –&gt; (int)(field ^ (field &gt;&gt;&gt; 32)) float –&gt; Float.floatToIntBits(field) double –&gt; Double.doubleToLongBits(field) –&gt; (long –&gt; int) 对象引用 –&gt; 直接调用 hashCode() 数组 –&gt; Arrays.hashCode(); result = 31 * result + hashCode; 检验相等实例是否有相同 hashCode。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public class PhoneNumber &#123; private final short areaCode; private final short prefix; private final short lineNumber; public PhoneNumber(short areaCode, short prefix, short lineNumber) &#123; rangeCheck(areaCode, 999, \"area code\"); rangeCheck(prefix, 999, \"prefix\"); rangeCheck(lineNumber, 9999, \"lineNumber\"); this.areaCode = areaCode; this.prefix = prefix; this.lineNumber = lineNumber; &#125; private void rangeCheck(int arg, int max, String name) &#123; if(arg &lt; 0 || arg &gt; max)&#123; new IllegalArgumentException(name + \": \" + arg); &#125; &#125; @Override public boolean equals(Object o) &#123; if (this == o) &#123; return true; &#125; if (o == null || !(o instanceof PhoneNumber)) &#123; return false; &#125; PhoneNumber that = (PhoneNumber) o; return lineNumber == that.lineNumber &amp;&amp; areaCode == that.areaCode &amp;&amp; prefix == that.prefix; &#125; @Override public int hashCode() &#123; int result = (int) areaCode; result = 31 * result + (int) prefix; result = 31 * result + (int) lineNumber; return result; &#125; @Override public String toString() &#123; return \"PhoneNumber&#123;\" + \"areaCode=\" + areaCode + \", prefix=\" + prefix + \", lineNumber=\" + lineNumber + '&#125;'; &#125;&#125; Tips: 删除冗余域。 计算 hashCode 开销较大时，可以将其缓存到类内部。创建时计算或首次调用 hashCode() 时计算。 第六章 枚举和注解 使用 enum 代替 int 常量 用实例域代替序数。 将特定枚举常量关联到特定的 int 值。 使用 EnumSet 代替位域 位域：使用或运算将多个常量合并到一个集合中。text.applyStyles(STYLE_BOLD | STYLE_ITALIC) text.applyStyles(EnumSet.of(Style.BOLD, Style.ITALIC)) 使用 EnumMap 代替序数索引 Map&lt;Herb.Type, Set&lt;Herb&gt;&gt; herbsByType = new EnumMap&lt;Herb.Type, Set&lt;Herb&gt;&gt;(Herb.Type.class); 多维：EnumMap&lt;..., EnumMap&lt;...&gt;&gt; 第七章 方法 检查参数有效性 public 方法使用异常 private 方法使用断言 必要时进行保护性拷贝 getXXX() setXXX() constructor 谨慎设计方法签名 命名方式要统一 参数不宜超过 3 个。可以通过创建对象来传递多个参数 参数类型优先使用接口 慎用重载 重载方法是在编译期确定的（静态绑定） 慎用可变参数 返回 0 长度的数组或集合，而不是 null 为所有导出的 API 元素编写文档注释 how to write doc comments 第八章 通用程序设计 将局部变量的作用域最小化 第一次使用时声明。 for-each &gt; for &gt; while 对含有一组元素的数据结构，实现 Iterable 接口 使用最合适的类型来存储数据 使用 StringBuilder 来连接字符串 通过接口引用对象（面向接口编程）","categories":[{"name":"Java基础","slug":"Java基础","permalink":"http://blog.jackhoo.cn/categories/Java基础/"}],"tags":[{"name":"java","slug":"java","permalink":"http://blog.jackhoo.cn/tags/java/"},{"name":"Java基础","slug":"Java基础","permalink":"http://blog.jackhoo.cn/tags/Java基础/"}]},{"title":"谈谈Java类加载机制","slug":"谈谈Java类加载机制","date":"2017-10-29T15:45:00.000Z","updated":"2018-03-23T17:19:12.133Z","comments":true,"path":"2017/10/29/谈谈Java类加载机制/","link":"","permalink":"http://blog.jackhoo.cn/2017/10/29/谈谈Java类加载机制/","excerpt":"","text":"谈谈 Java 类加载机制最近在学习 Tomcat 架构，其中很重要的一个模块是类加载器，因为以前学习的不够深入，所以趁这个机会好好把类加载机制搞明白。 Overview API for class loading java.lang.ClassLoader java.security.SecureClassLoader java.net.URLClassLoader Tomcat 8.5.15 class loading Mechanism Reference Overview 类加载器主要分为两类，一类是 JDK 默认提供的，一类是用户自定义的。JDK 默认提供三种类加载器 Bootstrap ClassLoader，启动类加载器，每次执行 java 命令时都会使用该加载器为虚拟机加载核心类。该加载器是由 native code 实现，而不是 Java 代码，加载类的路径为 &lt;JAVA_HOME&gt;/jre/lib。特别的 &lt;JAVA_HOME&gt;/jre/lib/rt.jar 中包含了 sun.misc.Launcher 类， 而 sun.misc.Launcher$ExtClassLoader 和 sun.misc.Launcher$AppClassLoader 都是 sun.misc.Launcher 的内部类，所以拓展类加载器和系统类加载器都是由启动类加载器加载的。 Extension ClassLoader, 拓展类加载器，用于加载拓展库中的类。拓展库路径为 &lt;JAVA_HOME&gt;/jre/lib/ext/。实现类为 sun.misc.Launcher$ExtClassLoader System ClassLoader, 系统类加载器。用于加载 CLASSPATH 中的类。实现类为 sun.misc.Launcher$AppClassLoader 用户自定义的类加载器 Custom ClassLoader, 一般都是 java.lang.ClassLoder 的子类 正统的类加载机制是基于双亲委派的，也就是当调用类加载器加载类时，首先将加载任务委派给双亲，若双亲无法加载成功时，自己才进行类加载。 在实例化一个新的类加载器时，我们可以为其指定一个 parent，即双亲，若未显式指定，则 System ClassLoader 就作为默认双亲。 具体的说，类加载任务是由 ClassLoader 的 loadClass() 方法来执行的，他会按照以下顺序加载类： 通过 findLoadedClass() 看该类是否已经被加载。该方法为 native code 实现，若已加载则返回。 若未加载则委派给双亲，parent.loadClass()，若成功则返回 若未成功，则调用 findClass() 方法加载类。java.lang.ClassLoader 中该方法只是简单的抛出一个 ClassNotFoundException 所以，自定义的 ClassLoader 都需要 Override findClass() 方法 API for class loadingjava.lang.ClassLoader ClassLoader 是一个抽象类。 待加载的类必须用 The Java™ Language Specification 定义的全类名，全类名的定义请查阅 The Form of a Binary。 给定一个全类名，类加载器应该去定位该类所在的位置。通用的策略是将全类名转换为类文件路径，然后通过类文件路径在文件系统中定位。 每一个加载到内存的类都由一个 Class 对象来表示，每一个 Class 对象都有一个指向加载该类的类加载器的引用。但是数组的 Class 对象是由 Java 运行时环境创建的，通过 Class.getClassLoader() 方法返回的是数组元素的类加载器，若数组元素是基本类型，则返回 null，若类是由 Bootstrap ClassLoader 加载的话也是返回 null 12345678910111213141516171819202122232425public class Main &#123; public static void main(String[] args) &#123; // Object 类在 &lt;java_home&gt;/jre/lib/rt.jar 中， // 由 Bootstrap ClassLoader 加载，由于该类加载器是由 native code 编写 // 所以输出为 null Object[] objects = new Object[5]; System.out.println(); System.out.println(objects.getClass().getClassLoader()); // ZipFileAttributes 类在 &lt;java_home&gt;/jre/lib/ext/zipfs.jar 中， // 由 Extension ClassLoader 加载， // 输出为 sun.misc.Launcher$ExtClassLoader@4b67cf4d ZipFileAttributes[] attributes = new ZipFileAttributes[5]; System.out.println(); System.out.println(attributes.getClass().getClassLoader()); // Main 类是自定义的类， // 默认由 System ClassLoader 加载， // 输出为 sun.misc.Launcher$AppClassLoader@18b4aac2 Main[] array = new Main[5]; array[0] = new Main(); System.out.println(); System.out.println(array.getClass().getClassLoader()); &#125;&#125; ClassLoader 默认支持并行加载，但是其子类必须调用 ClassLoader.registerAsParallelCapable() 来启用并行加载 一般来说,JVM 从本地文件系统加载类的行为是与平台有关的。 defineClass() 方法可以将字节流转换成一个 Class 对象。然后调用 Class.newInstance() 来创建类的实例 java.security.SecureClassLoader增加了一层权限验证，因为关注点不在安全，所以暂不讨论。 java.net.URLClassLoader该类加载器用来加载 URL 指定的 JAR 文件或目录中的类和资源，以 / 结尾的 URL 认为是目录，否则认为是 JAR 文件。 123456789101112131415161718192021222324252627// 尝试通过 URLClassLoader 来加载桌面下的 Test 类。public class Main &#123; public static void main(String[] args) &#123; try &#123; URL[] urls = new URL[1]; URLStreamHandler streamHandler = null; File classPath = new File(\"/home/chen/Desktop/\"); String repository = (new URL(\"file\", null, classPath.getCanonicalPath() + File.separator)) .toString(); urls[0] = new URL(null, repository, streamHandler); ClassLoader loader = new URLClassLoader(urls); Class testClass = loader.loadClass(\"Test\"); // output: java.net.URLClassLoader@7f31245a System.out.println(testClass.getClassLoader()); &#125; catch (MalformedURLException e) &#123; e.printStackTrace(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; catch (ClassNotFoundException e) &#123; e.printStackTrace(); &#125; &#125;&#125; Tomcat 8.5.15 class loading Mechanism Tomcat 使用正统的类加载机制(双亲委派),但部分地方做了改动。 Bootstrap classLoader 和 Extension classLoader 的作用不变 System classLoader 正常情况下加载的是 CLASSPATH 下的类，但是 Tomcat 的启动脚本并未使用该变量，而是从以下仓库下加载类： $CATALINA_HOME/bin/bootstrap.jar 包含了 Tomcat 的启动类。在该启动类中创建了 Common classLoader、Catalina classLoader、shared classLoader。因为 $CATALINA_BASE/conf/catalina.properties 中只对 common.loader 属性做了定义，server.loader 和 shared.loader 属性为空，所以默认情况下，这三个 classLoader 都是 CommonLoader。具体的代码逻辑可以查阅 org.apache.catalina.startup.Bootstrap 类的 initClassLoaders() 方法和 createClassLoader() 方法。 $CATALINA_BASE/bin/tomcat-juli.jar 包含了 Tomcat 日志模块所需要的实现类 $CATALINA_HOME/bin/commons-daemon.jar Common classLoader 是位于 Tomcat 应用服务器顶层的公用类加载器。由其加载的类可以由 Tomcat 自身类和所有应用程序使用。扫描路径由 $CATALINA_BASE/conf/catalina.properties 文件中的 common.loader 属性定义。默认是 $CATALINA_HOME/lib. catalina classLoader 用于加载服务器内部可见类，这些类应用程序不能访问。 shared classLoader 用于加载应用程序共享类，这些类服务器不会依赖。 Webapp classLoader 。每个应用程序都会有一个独一无二的 webapp classloader，他用来加载本应用程序 /WEB-INF/classes 和 /WEB-INF/lib 下的类。 特别的： Webapp classLoader 的默认行为会与正常的双亲委派模式不同： 从 Bootstrap classloader 加载 若没有，从 /WEB-INF/classes 加载 若没有，从 /WEB-INF/lib/*.jar 加载 若没有，则依次从 System、Common、shared 加载（该步骤使用双亲委派） 当然了，我们也可以通过配置来使 Webapp classLoader 严格按照双亲委派模式加载类： 通过在工程的 META-INF/context.xml（和 WEB-INF/classes 在同一目录下） 配置文件中添加 &lt;Loader delegate=&quot;true&quot;/&gt; 因为 Webapp classLoader 的实现类是 org.apache.catalina.loader.WebappLoader，他有一个属性叫 delegate， 用来控制类加载器的加载行为，默认为 false，我们可以使用 set 方法，将其设为 true 来启用严格双亲委派加载模式。 严格双亲委派模式加载步骤： 从 Bootstrap classloader 加载 若没有，则依次从 System、Common、shared 加载 若没有，从 /WEB-INF/classes 加载 若没有，从 /WEB-INF/lib/*.jar 加载 Reference The Java Class Loading Mechanism Java Classloader Class Loader HOW-TO - Apache Tomcat 8 《Tomcat 架构解析》 《深入理解 Java 虚拟机》","categories":[{"name":"Java基础","slug":"Java基础","permalink":"http://blog.jackhoo.cn/categories/Java基础/"}],"tags":[{"name":"java基础","slug":"java基础","permalink":"http://blog.jackhoo.cn/tags/java基础/"},{"name":"类加载","slug":"类加载","permalink":"http://blog.jackhoo.cn/tags/类加载/"}]},{"title":"三次握手四次挥手小记","slug":"三次握手四次挥手小记","date":"2017-10-29T14:59:00.000Z","updated":"2018-03-30T12:02:58.840Z","comments":true,"path":"2017/10/29/三次握手四次挥手小记/","link":"","permalink":"http://blog.jackhoo.cn/2017/10/29/三次握手四次挥手小记/","excerpt":"","text":"示意图!(示意图)[/images/tcp.png] 三次握手TCP是面向连接的，无论哪一方向另一方发送数据之前，都必须先在双方之间建立一条连接。在TCP/IP协议中，TCP 协议提供可靠的连接服务，连接是通过三次握手进行初始化的。三次握手的目的是同步连接双方的序列号和确认号 并交换 TCP窗口大小信息。 第一次握手：建立连接。客户端发送连接请求报文段，将SYN位置为1，Sequence Number为x;然后，客户端进入SYN_SEND状态，等待服务器的确认; 第二次握手：服务器收到SYN报文段。服务器收到客户端的SYN报文段，需要对这个SYN报文段进行确认，设置Acknowledgment Number为x+1(Sequence Number+1);同时，自己自己还要发送SYN请求信息，将SYN位置为1，Sequence Number为y;服务器端将上述所有信息放到一个报文段(即SYN+ACK报文段)中，一并发送给客户端，此时服务器进入SYN_RECV状态; 第三次握手：客户端收到服务器的SYN+ACK报文段。然后将Acknowledgment Number设置为y+1，向服务器发送ACK报文段，这个报文段发送完毕以后，客户端和服务器端都进入ESTABLISHED状态，完成TCP三次握手。 完成了三次握手，客户端和服务器端就可以开始传送数据。以上就是TCP三次握手的总体介绍。 四次握手当客户端和服务器通过三次握手建立了TCP连接以后，当数据传送完毕，肯定是要断开TCP连接的啊。那对于TCP的断开连接，这里就有了神秘的“四次挥手”。 第一次挥手：主机1(可以使客户端，也可以是服务器端)，设置Sequence Number和Acknowledgment Number，向主机2发送一个FIN报文段;此时，主机1进入FIN_WAIT_1状态;这表示主机1没有数据要发送给主机2了; 第二次挥手：主机2收到了主机1发送的FIN报文段，向主机1回一个ACK报文段，Acknowledgment Number为Sequence Number加1;主机1进入FIN_WAIT_2状态;主机2告诉主机1，我也没有数据要发送了，可以进行关闭连接了; 第三次挥手：主机2向主机1发送FIN报文段，请求关闭连接，同时主机2进入CLOSE_WAIT状态; 第四次挥手：主机1收到主机2发送的FIN报文段，向主机2发送ACK报文段，然后主机1进入TIME_WAIT状态;主机2收到主机1的ACK报文段以后，就关闭连接;此时，主机1等待2MSL后依然没有收到回复，则证明Server端已正常关闭，那好，主机1也可以关闭连接了。 为什么要三次握手？在谢希仁的《计算机网络》中是这样说的： 为了防止已失效的连接请求报文段突然又传送到了服务端，因而产生错误。 在书中同时举了一个例子，如下： “已失效的连接请求报文段”的产生在这样一种情况下：client发出的第一个连接请求报文段并没有丢失， 而是在某个网络结点长时间的滞留了，以致延误到连接释放以后的某个时间才到达server。本来这是一 个早已失效的报文段。但server收到此失效的连接请求报文段后，就误认为是client再次发出的一个新的连接请求。于是就向client发出确认报文段，同意建立连接。假设不采用“三次握手”，那么只要server发出确认，新的连接就建立了。由于现在client并没有发出建立连接的请求，因此不会理睬server的确认，也不会向server发送数据。但server却以为新的运输连接已经建立，并一直等待client发来数据。这样，server的很多资源就白白浪费掉了。采用“三次握手”的办法可以防止上述现象发生。” 例如刚才那种情况， client不会向server的确认发出确认。server由于收不到确认，就知道client并没有要求建立连接。” 这就很明白了，防止了服务器端的一直等待而浪费资源。 为什么要四次挥手?那四次挥手又是为何呢?TCP协议是一种面向连接的、可靠的、基于字节流的运输层通信协议。TCP是全双工 模式，这就意味着，当主机1发出FIN报文段时，只是表示主机1已经没有数据要发送了，主机1告诉主机2， 它的数据已经全部发送完毕了;但是，这个时候主机1还是可以接受来自主机2的数据;当主机2返回ACK报文 段时，表示它已经知道主机1没有数据发送了，但是主机2还是可以发送数据到主机1的;当主机2也发送了FIN 报文段时，这个时候就表示主机2也没有数据要发送了，就会告诉主机1，我也没有数据要发送了，之后彼此 就会愉快的中断这次TCP连接。如果要正确的理解四次挥手的原理，就需要了解四次挥手过程中的状态变化。 FIN_WAIT_1: 这个状态要好好解释一下，其实FIN_WAIT_1和FIN_WAIT_2状态的真正含义都是表示等 待对方的FIN报文。而这两种状态的区别是：FIN_WAIT_1状态实际上是当SOCKET在ESTABLISHED状态时， 它想主动关闭连接，向对方发送了FIN报文，此时该SOCKET即进入到FIN_WAIT_1状态。而当对方回应ACK报 文后，则进入到FIN_WAIT_2状态，当然在实际的正常情况下，无论对方何种情况下，都应该马上回应ACK 报文，所以FIN_WAIT_1状态一般是比较难见到的，而FIN_WAIT_2状态还有时常常可以用netstat看到。 (主动方) FIN_WAIT_2：上面已经详细解释了这种状态，实际上FIN_WAIT_2状态下的SOCKET，表示半连接，也即 有一方要求close连接，但另外还告诉对方，我暂时还有点数据需要传送给你(ACK信息)，稍后再关闭连接。 (主动方) CLOSE_WAIT：这种状态的含义其实是表示在等待关闭。怎么理解呢?当对方close一个SOCKET后发送FIN 报文给自己，你系统毫无疑问地会回应一个ACK报文给对方，此时则进入到CLOSE_WAIT状态。接下来呢，实 际上你真正需要考虑的事情是察看你是否还有数据发送给对方，如果没有的话，那么你也就可以 close这个 SOCKET，发送FIN报文给对方，也即关闭连接。所以你在CLOSE_WAIT状态下，需要完成的事情是等待你去关 闭连接。(被动方) LAST_ACK: 这个状态还是比较容易好理解的，它是被动关闭一方在发送FIN报文后，最后等待对方的ACK报 文。当收到ACK报文后，也即可以进入到CLOSED可用状态了。(被动方) TIME_WAIT: 表示收到了对方的FIN报文，并发送出了ACK报文，就等2MSL后即可回到CLOSED可用状态了。 如果FINWAIT1状态下，收到了对方同时带FIN标志和ACK标志的报文时，可以直接进入到TIME_WAIT状态，而无 须经过FIN_WAIT_2状态。(主动方) CLOSED: 表示连接中断。","categories":[{"name":"网络","slug":"网络","permalink":"http://blog.jackhoo.cn/categories/网络/"}],"tags":[{"name":"TCP","slug":"TCP","permalink":"http://blog.jackhoo.cn/tags/TCP/"}]},{"title":"读一读ConcurrentHashMap,收获也颇多","slug":"读一读ConcurrentHashMap,收获也颇多","date":"2017-10-23T16:50:00.000Z","updated":"2018-03-23T17:29:04.689Z","comments":true,"path":"2017/10/24/读一读ConcurrentHashMap,收获也颇多/","link":"","permalink":"http://blog.jackhoo.cn/2017/10/24/读一读ConcurrentHashMap,收获也颇多/","excerpt":"","text":"一、背景： 线程不安全的HashMap 因为多线程环境下，使用Hashmap进行put操作会引起死循环，导致CPU利用率接近100%，所以在并发情况下不能使用HashMap。 效率低下的HashTable容器 HashTable容器使用synchronized来保证线程安全，但在线程竞争激烈的情况下HashTable的效率非常低下。因为当一个线程访问HashTable的同步方法时，其他线程访问HashTable的同步方法时，可能会进入阻塞或轮询状态。如线程1使用put进行添加元素，线程2不但不能使用put方法添加元素，并且也不能使用get方法来获取元素，所以竞争越激烈效率越低。 锁分段技术 !技术图 HashTable容器在竞争激烈的并发环境下表现出效率低下的原因，是因为所有访问HashTable的线程都必须竞争同一把锁，那假如容器里有多把锁，每一把锁用于锁容器其中一部分数据，那么当多线程访问容器里不同数据段的数据时，线程间就不会存在锁竞争，从而可以有效的提高并发访问效率，这就是ConcurrentHashMap所使用的锁分段技术，首先将数据分成一段一段的存储，然后给每一段数据配一把锁，当一个线程占用锁访问其中一个段数据的时候，其他段的数据也能被其他线程访问。有些方法需要跨段，比如size()和containsValue()，它们可能需要锁定整个表而而不仅仅是某个段，这需要按顺序锁定所有段，操作完毕后，又按顺序释放所有段的锁。这里“按顺序”是很重要的，否则极有可能出现死锁，在ConcurrentHashMap内部，段数组是final的，并且其成员变量实际上也是final的，但是，仅仅是将数组声明为final的并不保证数组成员也是final的，这需要实现上的保证。这可以确保不会出现死锁，因为获得锁的顺序是固定的。 ConcurrentHashMap是由Segment数组结构和HashEntry数组结构组成。Segment是一种可重入锁ReentrantLock，在ConcurrentHashMap里扮演锁的角色，HashEntry则用于存储键值对数据。一个ConcurrentHashMap里包含一个Segment数组，Segment的结构和HashMap类似，是一种数组和链表结构， 一个Segment里包含一个HashEntry数组，每个HashEntry是一个链表结构的元素， 每个Segment守护者一个HashEntry数组里的元素,当对HashEntry数组的数据进行修改时，必须首先获得它对应的Segment锁。 二、应用场景当有一个大数组时需要在多个线程共享时就可以考虑是否把它给分层多个节点了，避免大锁。并可以考虑通过hash算法进行一些模块定位。其实不止用于线程，当设计数据表的事务时（事务某种意义上也是同步机制的体现），可以把一个表看成一个需要同步的数组，如果操作的表数据太多时就可以考虑事务分离了（这也是为什么要避免大表的出现），比如把数据进行字段拆分，水平分表等. 三、源码解读 ConcurrentHashMap(1.7及之前)中主要实体类就是三个：ConcurrentHashMap（整个Hash表）,Segment（桶），HashEntry（节点），对应上面的图可以看出之间的关系123456789101112/** * The segments, each of which is a specialized hash table */ final Segment&lt;K,V&gt;[] segments;不变(Immutable)和易变(Volatile) ConcurrentHashMap完全允许多个读操作并发进行，读操作并不需要加锁。如果使用传统的技术，如HashMap中的实现，如果允许可以在hash链的中间添加或删除元素，读操作不加锁将得到不一致的数据。ConcurrentHashMap实现技术是保证HashEntry几乎是不可变的。HashEntry代表每个hash链中的一个节点，其结构如下所示： static final class HashEntry&lt;K,V&gt; &#123; final K key; final int hash; volatile V value; final HashEntry&lt;K,V&gt; next; &#125; 可以看到除了value不是final的，其它值都是final的，这意味着不能从hash链的中间或尾部添加或删除节点，因为这需要修改next 引用值，所有的节点的修改只能从头部开始。对于put操作，可以一律添加到Hash链的头部。但是对于remove操作，可能需要从中间删除一个节点，这就需要将要删除节点的前面所有节点整个复制一遍，最后一个节点指向要删除结点的下一个结点。这在讲解删除操作时还会详述。为了确保读操作能够看到最新的值，将value设置成volatile，这避免了加锁。其它 为了加快定位段以及段中hash槽的速度，每个段hash槽的的个数都是2^n，这使得通过位运算就可以定位段和段中hash槽的位置。当并发级别为默认值16时，也就是段的个数，hash值的高4位决定分配在哪个段中。但是我们也不要忘记《算法导论》给我们的教训：hash槽的的个数不应该是 2^n，这可能导致hash槽分配不均，这需要对hash值重新再hash一次。（这段似乎有点多余了 ） 定位操作：123final Segment&lt;K,V&gt; segmentFor(int hash) &#123; return segments[(hash &gt;&gt;&gt; segmentShift) &amp; segmentMask]; &#125; 既然ConcurrentHashMap使用分段锁Segment来保护不同段的数据，那么在插入和获取元素的时候，必须先通过哈希算法定位到Segment。可以看到ConcurrentHashMap会首先使用Wang/Jenkins hash的变种算法对元素的hashCode进行一次再哈希。再哈希，其目的是为了减少哈希冲突，使元素能够均匀的分布在不同的Segment上，从而提高容器的存取效率。假如哈希的质量差到极点，那么所有的元素都在一个Segment中，不仅存取元素缓慢，分段锁也会失去意义。我做了一个测试，不通过再哈希而直接执行哈希计算。 1234System.out.println(Integer.parseInt(\"0001111\", 2) &amp; 15);System.out.println(Integer.parseInt(\"0011111\", 2) &amp; 15);System.out.println(Integer.parseInt(\"0111111\", 2) &amp; 15);System.out.println(Integer.parseInt(\"1111111\", 2) &amp; 15); 计算后输出的哈希值全是15，通过这个例子可以发现如果不进行再哈希，哈希冲突会非常严重，因为只要低位一样，无论高位是什么数，其哈希值总是一样。我们再把上面的二进制数据进行再哈希后结果如下，为了方便阅读，不足32位的高位补了0，每隔四位用竖线分割下。 0100｜0111｜0110｜0111｜1101｜1010｜0100｜11101111｜0111｜0100｜0011｜0000｜0001｜1011｜10000111｜0111｜0110｜1001｜0100｜0110｜0011｜11101000｜0011｜0000｜0000｜1100｜1000｜0001｜1010 可以发现每一位的数据都散列开了，通过这种再哈希能让数字的每一位都能参加到哈希运算当中，从而减少哈希冲突。ConcurrentHashMap通过以下哈希算法定位segment。默认情况下segmentShift为28，segmentMask为15，再哈希后的数最大是32位二进制数据，向右无符号移动28位，意思是让高4位参与到hash运算中， (hash &gt;&gt;&gt; segmentShift) &amp; segmentMask的运算结果分别是4，15，7和8，可以看到hash值没有发生冲突。123final Segment&lt;K,V&gt; segmentFor(int hash) &#123; return segments[(hash &gt;&gt;&gt; segmentShift) &amp; segmentMask];&#125; 数据结构 所有的成员都是final的，其中segmentMask和segmentShift主要是为了定位段，参见上面的segmentFor方法。 关于Hash表的基础数据结构，这里不想做过多的探讨。Hash表的一个很重要方面就是如何解决hash冲突，ConcurrentHashMap 和HashMap使用相同的方式，都是将hash值相同的节点放在一个hash链中。与HashMap不同的是，ConcurrentHashMap使用多个子Hash表，也就是段(Segment)。每个Segment相当于一个子Hash表，它的数据成员如下：1234567891011121314151617181920212223242526272829303132static final class Segment&lt;K,V&gt; extends ReentrantLock implements Serializable &#123; /** * The number of elements in this segment's region. */ transient volatileint count; /** * Number of updates that alter the size of the table. This is * used during bulk-read methods to make sure they see a * consistent snapshot: If modCounts change during a traversal * of segments computing size or checking containsValue, then * we might have an inconsistent view of state so (usually) * must retry. */ transient int modCount; /** * The table is rehashed when its size exceeds this threshold. * (The value of this field is always &lt;tt&gt;(int)(capacity * * loadFactor)&lt;/tt&gt;.) */ transient int threshold; /** * The per-segment table. */ transient volatile HashEntry&lt;K,V&gt;[] table; /** * The load factor for the hash table. Even though this value * is same for all segments, it is replicated to avoid needing * links to outer object. * @serial */ final float loadFactor; &#125; count用来统计该段数据的个数，它是volatile，它用来协调修改和读取操作，以保证读取操作能够读取到几乎最新的修改。协调方式是这样的，每次修改操作做了结构上的改变，如增加/删除节点(修改节点的值不算结构上的改变)，都要写count值，每次读取操作开始都要读取count的值。这利用了 Java 5中对volatile语义的增强，对同一个volatile变量的写和读存在happens-before关系。modCount统计段结构改变的次数，主要是为了检测对多个段进行遍历过程中某个段是否发生改变，在讲述跨段操作时会还会详述。threashold用来表示需要进行rehash的界限值。table数组存储段中节点，每个数组元素是个hash链，用HashEntry表示。table也是volatile，这使得能够读取到最新的 table值而不需要同步。loadFactor表示负载因子。删除操作remove(key)1234public V remove(Object key) &#123; hash = hash(key.hashCode()); return segmentFor(hash).remove(key, hash, null); &#125; 整个操作是先定位到段，然后委托给段的remove操作。当多个删除操作并发进行时，只要它们所在的段不相同，它们就可以同时进行。下面是Segment的remove方法实现：123456789101112131415161718192021222324252627282930313233V remove(Object key, int hash, Object value) &#123; lock(); try &#123; int c = count - 1; HashEntry&lt;K,V&gt;[] tab = table; int index = hash &amp; (tab.length - 1); HashEntry&lt;K,V&gt; first = tab[index]; HashEntry&lt;K,V&gt; e = first; while (e != null &amp;&amp; (e.hash != hash || !key.equals(e.key))) e = e.next; V oldValue = null; if (e != null) &#123; V v = e.value; if (value == null || value.equals(v)) &#123; oldValue = v; // All entries following removed node can stay // in list, but all preceding ones need to be // cloned. ++modCount; HashEntry&lt;K,V&gt; newFirst = e.next; *for (HashEntry&lt;K,V&gt; p = first; p != e; p = p.next) *newFirst = new HashEntry&lt;K,V&gt;(p.key, p.hash, newFirst, p.value); tab[index] = newFirst; count = c; // write-volatile &#125; &#125; return oldValue; &#125; finally &#123; unlock(); &#125; &#125; get操作不需要锁。 除非读到的值是空的才会加锁重读，我们知道HashTable容器的get方法是需要加锁的，那么ConcurrentHashMap的get操作是如何做到不加锁的呢？原因是它的get方法里将要使用的共享变量都定义成volatile 第一步是访问count变量，这是一个volatile变量，由于所有的修改操作在进行结构修改时都会在最后一步写count 变量，通过这种机制保证get操作能够得到几乎最新的结构更新。对于非结构更新，也就是结点值的改变，由于HashEntry的value变量是 volatile的，也能保证读取到最新的值。 接下来就是根据hash和key对hash链进行遍历找到要获取的结点，如果没有找到，直接访回null。对hash链进行遍历不需要加锁的原因在于链指针next是final的。但是头指针却不是final的，这是通过getFirst(hash)方法返回，也就是存在 table数组中的值。这使得getFirst(hash)可能返回过时的头结点，例如，当执行get方法时，刚执行完getFirst(hash)之后，另一个线程执行了删除操作并更新头结点，这就导致get方法中返回的头结点不是最新的。这是可以允许，通过对count变量的协调机制，get能读取到几乎最新的数据，虽然可能不是最新的。要得到最新的数据，只有采用完全的同步。 最后，如果找到了所求的结点，判断它的值如果非空就直接返回，否则在有锁的状态下再读一次。这似乎有些费解，理论上结点的值不可能为空，这是因为 put的时候就进行了判断，如果为空就要抛NullPointerException。空值的唯一源头就是HashEntry中的默认值，因为 HashEntry中的value不是final的，非同步读取有可能读取到空值。仔细看下put操作的语句：tab[index] = new HashEntry&lt;K,V&gt;(key, hash, first, value)，在这条语句中，HashEntry构造函数中对value的赋值以及对tab[index]的赋值可能被重新排序，这就可能导致结点的值为空。这里当v为空时，可能是一个线程正在改变节点，而之前的get操作都未进行锁定，根据bernstein条件，读后写或写后读都会引起数据的不一致，所以这里要对这个e重新上锁再读一遍，以保证得到的是正确值。12345678V readValueUnderLock(HashEntry&lt;K,V&gt; e) &#123; lock(); try &#123; return e.value; &#125; finally &#123; unlock(); &#125; &#125; 如用于统计当前Segement大小的count字段和用于存储值的HashEntry的value。定义成volatile的变量，能够在线程之间保持可见性，能够被多线程同时读，并且保证不会读到过期的值，但是只能被单线程写（有一种情况可以被多线程写，就是写入的值不依赖于原值），在get操作里只需要读不需要写共享变量count和value，所以可以不用加锁。之所以不会读到过期的值，是根据java内存模型的happen before原则，对volatile字段的写入操作先于读操作，即使两个线程同时修改和获取volatile变量，get操作也能拿到最新的值，这是用volatile替换锁的经典应用场景 put操作同样地put操作也是委托给段的put方法。下面是段的put方法：1234567891011121314151617181920212223242526272829V put(K key, int hash, V value, boolean onlyIfAbsent) &#123; lock(); try &#123; int c = count; if (c++ &gt; threshold) // ensure capacity rehash(); HashEntry&lt;K,V&gt;[] tab = table; int index = hash &amp; (tab.length - 1); HashEntry&lt;K,V&gt; first = tab[index]; HashEntry&lt;K,V&gt; e = first; while (e != null &amp;&amp; (e.hash != hash || !key.equals(e.key))) e = e.next; V oldValue; if (e != null) &#123; oldValue = e.value; if (!onlyIfAbsent) e.value = value; &#125; else &#123; oldValue = null; ++modCount; tab[index] = new HashEntry&lt;K,V&gt;(key, hash, first, value); count = c; // write-volatile &#125; return oldValue; &#125; finally &#123; unlock(); &#125; &#125; 该方法也是在持有段锁(锁定整个segment)的情况下执行的，这当然是为了并发的安全，修改数据是不能并发进行的，必须得有个判断是否超限的语句以确保容量不足时能够rehash。接着是找是否存在同样一个key的结点，如果存在就直接替换这个结点的值。否则创建一个新的结点并添加到hash链的头部，这时一定要修改modCount和count的值，同样修改count的值一定要放在最后一步。put方法调用了rehash方法，reash方法实现得也很精巧，主要利用了table的大小为2^n，这里就不介绍了。而比较难懂的是这句int index = hash &amp; (tab.length - 1)，原来segment里面才是真正的hashtable，即每个segment是一个传统意义上的hashtable,如上图，从两者的结构就可以看出区别，这里就是找出需要的entry在table的哪一个位置，之后得到的entry就是这个链的第一个节点，如果e!=null，说明找到了，这是就要替换节点的值（onlyIfAbsent == false），否则，我们需要new一个entry，它的后继是first，而让tab[index]指向它，什么意思呢？实际上就是将这个新entry插入到链头，剩下的就非常容易理解了 由于put方法里需要对共享变量进行写入操作，所以为了线程安全，在操作共享变量时必须得加锁。Put方法首先定位到Segment，然后在Segment里进行插入操作。插入操作需要经历两个步骤，第一步判断是否需要对Segment里的HashEntry数组进行扩容，第二步定位添加元素的位置然后放在HashEntry数组里。是否需要扩容。在插入元素前会先判断Segment里的HashEntry数组是否超过容量（threshold），如果超过阀值，数组进行扩容。值得一提的是，Segment的扩容判断比HashMap更恰当，因为HashMap是在插入元素后判断元素是否已经到达容量的，如果到达了就进行扩容，但是很有可能扩容之后没有新元素插入，这时HashMap就进行了一次无效的扩容。如何扩容。扩容的时候首先会创建一个两倍于原容量的数组，然后将原数组里的元素进行再hash后插入到新的数组里。为了高效ConcurrentHashMap不会对整个容器进行扩容，而只对某个segment进行扩容。 另一个操作是containsKey，这个实现就要简单得多了，因为它不需要读取值： 1234567891011boolean containsKey(Object key, int hash) &#123; if (count != 0) &#123; // read-volatile HashEntry&lt;K,V&gt; e = getFirst(hash); while (e != null) &#123; if (e.hash == hash &amp;&amp; key.equals(e.key)) returntrue; e = e.next; &#125; &#125; returnfalse; &#125; size()操作 如果我们要统计整个ConcurrentHashMap里元素的大小，就必须统计所有Segment里元素的大小后求和。Segment里的全局变量count是一个volatile变量，那么在多线程场景下，我们是不是直接把所有Segment的count相加就可以得到整个ConcurrentHashMap大小了呢？不是的，虽然相加时可以获取每个Segment的count的最新值，但是拿到之后可能累加前使用的count发生了变化，那么统计结果就不准了。所以最安全的做法，是在统计size的时候把所有Segment的put，remove和clean方法全部锁住，但是这种做法显然非常低效。 因为在累加count操作过程中，之前累加过的count发生变化的几率非常小，所以ConcurrentHashMap的做法是先尝试2次通过不锁住Segment的方式来统计各个Segment大小，如果统计的过程中，容器的count发生了变化，则再采用加锁的方式来统计所有Segment的大小。 那么ConcurrentHashMap是如何判断在统计的时候容器是否发生了变化呢？使用modCount变量，在put , remove和clean方法里操作元素前都会将变量modCount进行加1，那么在统计size前后比较modCount是否发生变化，从而得知容器的大小是否发生变化。","categories":[{"name":"Java基础","slug":"Java基础","permalink":"http://blog.jackhoo.cn/categories/Java基础/"}],"tags":[{"name":"java","slug":"java","permalink":"http://blog.jackhoo.cn/tags/java/"},{"name":"Java基础","slug":"Java基础","permalink":"http://blog.jackhoo.cn/tags/Java基础/"}]},{"title":"ThreadPoolExecutor源码剖析","slug":"ThreadPoolExecutor源码剖析","date":"2017-10-23T15:45:00.000Z","updated":"2018-03-23T16:38:25.809Z","comments":true,"path":"2017/10/23/ThreadPoolExecutor源码剖析/","link":"","permalink":"http://blog.jackhoo.cn/2017/10/23/ThreadPoolExecutor源码剖析/","excerpt":"","text":"ThreadPoolExecutor 源码剖析源码基于 JDK9 概览 继承结构 状态转换 个性定制 Core and maximum pool sizes On-demand construction Creating new threads Keep-alive times Queuing Rejected tasks Hook methods Queue maintenance Finalization 任务处理流程 最佳实践 参考 概览ThreadPoolExecutor 为每个提交的任务分配一个线程处理，是一种 ExecutorService 实现。通常使用 Executors 的工厂方法来进行配置。 因为减少了每个任务调度的开销，所以它能在执行大量异步任务的场景中提供更好的性能。并且它提供了一种限定和管理资源(比如线程)的方式。他也会保存一些基本的统计信息，比如已完成的任务数量。 一般情况下我们使用 Executors 的工厂方法来创建相应的实例。 Executors.newCachedThreadPool()，线程数量没有上界(Integer.MAX_VALUE)，有新任务提交并且没有空闲线程时，创建一个新线程执行该任务，每个线程空闲时间为 60s, 60s 空闲后线程会被移出缓存。使用 SynchronousQueue 作为任务队列的实现类。适用于执行大量生命周期短的异步任务。 Executors.newFixedThreadPool(int)，固定容量的线程池。使用 LinkedBlockingQueue 作为任务队列的实现类。当新任务到达时，创建新线程，当线程数达到上限时，将任务放到队列中，任务队列中任务数量没有上界。当线程创建之后就一直存在直至显式的调用 shutdown() 方法。 Executors.newSingleThreadExecutor()，单个 Worker 的线程池。和 newFixedThreadPool(1) 类似，区别在于这个实例经过了一次封装，不能对该实例的参数进行重配置，并且实现了 finalize() 方法，能够在 GC 时调用 shutdown() 方法关闭该线程池。 继承结构 ThreadPoolExecutor 实现了 Executor 和 ExecutorService 两个接口。 Executor 是执行已提交任务的对象。这个接口提供了一种分离任务提交和任务执行细节的机制。用户只需要通过 execute() 方法提交任务即可，不用显式的创建线程。但使用该接口并不意味着就是异步执行，比如我们实现一个 Executor 类，在 execute(Runnable r) 中直接调用任务的 run() 方法。 ExecutorService 提供了一些管理终止和能够输出 Future (用来跟踪异步任务进度)的方法。提供了两个用来 shutdown 的方法： shutdown()。允许之前已提交的任务执行完毕。 shutdownNow()。不允许任务队列中的任务再执行并且试图去中断正在执行的任务。 ExecutorService 在不用时应该 shutdown 来允许回收其占用的资源。 状态转换 线程池的状态在 ThreadPoolExecutor 中的实际表示方式是一个 AtomicInteger 类型的成员变量的高三位(因为有 5 种状态)，名称为 ctl。 ctl 是 32 位的整型变量，他封装了两个变量： 线程池运行状态。高三位。 RUNNING: 111 SHUTDOWN: 000 STOP: 001 TIDYING: 010 TERMINATED: 011 有效工作线程数。低 29 位。 因为 ctl 是 AtomicInteger 的实例，其上的操作基于 CAS，是线程安全的。 shutdown() advanceRunState(SHUTDOWN); 首先将运行状态修改为 SHUTDOWN此时当有新任务提交时直接抛出 RejectedExecutionException 来拒绝服务。 interruptIdleWorkers() 通过调用 Worker 线程的 interrupt() 方法试图中断空闲 worker。// todo t.interrupt() 方法会对那些线程状态有效？成功调用会产生什么影响？Java 的线程状态和操作系统内部线程状态之间有什么关系？此处涉及的知识面稍广，浪费了一些时间依旧没能理解，把 ThreadPoolExecutor 过完以后再系统解决。 tryTerminate() 只对于运行状态为 STOP 或 SHUTDOWN+任务队列为空两种情况， 当 Worker 数量未减到 0 之前，每次调用会尝试中断一个 Worker 线程。当任务队列为不为空时，Worker 线程处理完正在处理的任务，会从工作队列中取出未处理的任务继续工作，循环这个过程至任务队列为空，Worker 获取不到要处理的任务时会将其从 Worker 集中移除，worker 数量减一，然后在 processWorkerExit() 方法中再次调用 tryTerminate() 。当 Worker 线程数量减到 0 以后再调用该方法时，会将运行状态修改为 TIDYING 并调用 terminated() 方法。ThreadPoolExextor 中该方法为空函数所以 TIDYING 和 TERMINATED 两个状态基本没有区别。 shutdownNow() advanceRunState(STOP) 首先将运行状态修改为 STOP 此时当有新任务提交时直接抛出 RejectedExecutionException 来拒绝服务。 interruptWorkers(); drainQueue()，直接清空任务队列 tryTerminate() 个性定制Core and maximum pool sizesThreadPoolExecutor 会依照 corePoolSize 和 maximumPoolSize 两个字段来动态调整线程池的大小。新任务提交过来时，如果当前活动的线程数少于 corePoolSize 会创建一个新线程来处理这个新任务即使当前有空闲线程。如果当前线程数大于 corePoolSize 小于 maximumPoolSize 且任务队列已满时也会创建新线程。 配置两个属性相等时可以获得固定容量的线程池。 将 maximumPoolSize 设为一个很大的数(比如 Integer.MAX_VAlUE)时，可以获得一个无上界的线程池，可以用来处理任意数量的并发任务。(Tips: 线程过多并不合适，因为物理机的 CPU 数量有限，无法同时处理那么多线程，只会白白占用资源，所以这个属性可以根据实际物理机 CPU 数量来配置。) 通常来说这两个属性，只通过构造器来配置，但是 ThreadPoolExecutor 也提供了 setter 方法可以在运行时配置。 On-demand construction如果在构造 ThreadPoolExecutor 时，任务队列中已经有要处理的任务了，那么在创建好以后，可用通过直接调用 prestartCoreThread() 或 prestartAllCoreThreads() 来创建核心线程去处理这些任务。否则这些任务就只能在有新任务提交过来以后才能开始处理。 Creating new threads新线程是通过 ThreadFactory 来创建的，如果在构造时未指定，就使用默认的 java.util.concurrent.Executors.DefaultThreadFactory。该 ThreadFactory 创建的线程都属于同一个线程组、Thread.NORM_PRIORITY 优先级、用户线程。 我们可以通过指定一个不同的线程工厂来修改线程名、线程组、优先级、线程守护状态等等。 Keep-alive times如果当前线程数量超出了 corePoolSize，超出的那部分非核心线程会在空闲超出 keepAliveTime 时被终止。这能够线程池活跃状态不足时及时回收占用的资源。该参数也可以使用 setKeepAliveTime(long, TimeUnit) 来运行时动态修改。可以通过使用 Long.MAX_VALUE TimeUnit.NANOSECONDS 两个参数来禁用线程回收。默认情况下核心线程超时不回收，可以通过配置 keepAliveTime 和 allowCoreThreadTimeOut 来允许核心线程超时回收。 Queuing任意的 BlockingQueue 实现都可以作为任务队列。任务队列的使用对线程池收缩会有一定影响： 如果当前线程数少于 corePoolSize，新提交的任务会直接提交给新创建的线程。 如果当前线程数不少于 corePoolSize，新提交的任务会提交到任务队列中。 如果新任务无法提交到任务队列(队列已满)，会尝试创建一个新线程，如果线程数达到了 maximumPoolSize 而导致新线程无法创建则该任务会被拒绝。 一般来说，任务队列有三种使用策略： 直接交付。直接将到达的任务交付给线程，而不是将任务暂存起来。当没有空闲线程可用时直接新建线程。这种方式通常需要无上界的 maximumPoolSize 来防止拒绝服务。当然这种方式也有缺点，新任务到达的速度超过任务处理的速度时，新建的线程数量会越来越多。耗费内存。常常使用 SynchronousQueue 作为任务队列的实现类。 无界队列。使用无界队列的话，执行任务的线程数不会超过 corePoolSize 的大小，但核心线程都无空闲时，新到的任务会添加到任务队列。当新任务到达的速度超过了任务处理的速度时，任务会积累的越来越多。常常使用 LinkedBlockingQueue 作为任务队列的实现类。 有界队列。和有限的 maximumPoolSize 结合使用能够防止资源耗尽。但是队列的大小和 maximumPoolSize 的大小配置权衡起来会更难一些。大队列加小容量线程池可以最小化 CPU使用率、OS 资源和上下文切换的开销。但是有可能吞吐量会比较低，如果任务频繁阻塞(I/O操作)的话无法最优使用 CPU 资源。如果使用小队列加大容量的线程池，可以保证 CPU 的使用率，但是上下文调度的开销可能会过大，这也会降低吞吐量。常使用 ArrayBlockingQueue 作为任务队列的实现类。 Rejected tasks Executor 状态不再是 RUNNING（已经被 SHUTDOWN） 任务队列已满并且线程数量达到最大值，已达到饱和状态。 Hook methodsThreadPoolExecutor 也提供了一些其他方法，子类可以重写这些方法来提供额外的支持：重新初始化 ThreadLocals，收集统计信息，添加日志等等。 beforeExecute(Thread, Runnable)， //任务执行前调用 afterExecute(Runnable, Throwable) //任务执行后调用 terminated() // Executor 状态转为 TIDYING 后调用 Queue maintenance getQueue() 可以访问任务队列，但是只鼓励用于监控与调试。 remove(Runnable) 和 purge() 方法可以用于取消尚未执行的任务。remove(Runnable) 直接从任务队列删除，purge() 从任务队列批量删除已取消的 Future Finalization当线程池没有到 GC Roots 的引用并且 Worker 数为 0 时会被自动回收。 如果想要在忘记调用 shutdown() 时也能确保未被引用的线程池被回收的话，需要确保未使用的线程最终都被能终止。可以设置合适的 keepAliveTime 以及 allowCoreThreadTimeOut。 任务处理流程我们以一个简单例子来剖析一下整个过程。 1234567891011121314151617181920212223242526272829package me.rainstorm;import java.util.concurrent.ExecutorService;import java.util.concurrent.LinkedBlockingDeque;import java.util.concurrent.ThreadPoolExecutor;import java.util.concurrent.TimeUnit;/** * * @author baochen.zhang * @date 2017.12.4 */public class ThreadPoolExecutorDemo &#123; private static final int THREAD_POOL_SIZE = Runtime.getRuntime().availableProcessors() + 2; private static ExecutorService exe = new ThreadPoolExecutor(THREAD_POOL_SIZE, THREAD_POOL_SIZE, 60, TimeUnit.SECONDS, new LinkedBlockingDeque&lt;&gt;(100)); &#123; ((ThreadPoolExecutor)exe).allowCoreThreadTimeOut(true); &#125; public static void main(String[] args) &#123; exe.execute(() -&gt; System.out.println(\"Hello world\")); exe.shutdown(); exe = null; &#125;&#125; ctl 变量之前已经提到了，作为一个控制变量用来控制线程池的状态和工作线程数。默认值是 RUNNING | 0，即状态为 RUNNING，Worker 线程数为 0; 在 Demo 中并未指定线程工厂，ThreadPoolExecutor 使用 Executors 提供的默认线程工厂。 因为只有一个任务，所以 main 方法中在提交完这个任务后，直接调用了 shutdown() 方法，并将其赋为 null 便于在任务执行完毕后回收资源，一般情况下推荐在所有任务都提交到线程池以后再调用 shutdown，否则之后的任务直接会被拒绝掉。 因为只有一个任务，且允许核心线程超时，所以该线程在 getTask() 过程中会超时，然后返回 null，进入 processWorkerExit() 流程。 线程池在进入 TERMINATED 状态后就可以被 GC 了。 最佳实践一般情况下使用 Executors 的工厂方法来创建即可适用于大多数场景。需要配置的话参考 个性定制 来配置更合适自己项目的 ThreadPoolExecutor。 参考 Java SE 9 &amp; JDK 9 – java.util.concurrent Java SE 9 &amp; JDK 9 – Executors Java SE 9 &amp; JDK 9 – Executor Java SE 9 &amp; JDK 9 – ExecutorService Java SE 9 &amp; JDK 9 – ThreadPoolExecutor Java SE 9 &amp; JDK 9 – Source Code What is Daemon thread in Java? 深入理解java线程池—ThreadPoolExecutor Java 中, 为什么一个对象的实例方法在执行完成之前其对象可以被 GC 回收?","categories":[{"name":"Java基础","slug":"Java基础","permalink":"http://blog.jackhoo.cn/categories/Java基础/"}],"tags":[{"name":"多线程","slug":"多线程","permalink":"http://blog.jackhoo.cn/tags/多线程/"},{"name":"线程池","slug":"线程池","permalink":"http://blog.jackhoo.cn/tags/线程池/"}]},{"title":"RandomAccessFile类的使用小结","slug":"RandomAccessFile类的使用小结","date":"2017-10-23T07:26:00.000Z","updated":"2018-03-23T11:15:14.617Z","comments":true,"path":"2017/10/23/RandomAccessFile类的使用小结/","link":"","permalink":"http://blog.jackhoo.cn/2017/10/23/RandomAccessFile类的使用小结/","excerpt":"","text":"字符、字节、位理清楚这些基础的东西，对文件操作会有很大的帮助 在计算机中最小的单元是位，即bit,1 byte = 8 bit 在Java中最小的单位是byte,一个字节只占8位,在java的IO流中最小的单位就是字节，InputStream#read()方法读取一个字节并返回，如果到达文件末尾则为返回-1 在java中一个int占4个字节，一个char类型占2个字节，一个字母和数字占1个字节，一个中文汉字占2个字节，为何一个char要占两个字节呢，因为java采用unicode，2个字节（16位）来表示一个字符 RandomAccessFile类的主要功能 对象声明：RandomAccessFile raf = newRandomAccessFile(File file, String mode); 其中参数 mode 的值可选 “r”：可读，”w” ：可写，”rw”：如果使用此模式，如果此文件不存在，则会自动创建； 获取当前文件指针位置：int RandowAccessFile.getFilePointer(); 改变文件指针位置（相对位置、绝对位置）： 绝对位置：RandowAccessFile.seek(int index); 相对位置：RandowAccessFile.skipByte(int step);(相对当前位置) 给写入文件预留空间：RandowAccessFile.setLength(long len); 案例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566package RandomAccessFile; /** * Copyright (C), 2008-2018, JackHoo * FileName: Test * Author: JackHoo * Date: 2017/9/23 16:18 * Description: */import java.io.IOException;import java.io.RandomAccessFile;public class Test &#123; public static void main(String[] args) throws IOException &#123; Test test = new Test(); test.readFile(\"test.txt\"); &#125; public void writeFile(String filename) throws IOException &#123; RandomAccessFile raf = new RandomAccessFile(filename, \"rw\"); String name = null; int age = 0; name = \"zhangsan\"; // 字符串长度为8 age = 30; raf.writeBytes(name); raf.writeInt(age); name = \"lisi \"; // 字符串长度为8 age = 31; // 数字的长度为4 raf.writeBytes(name); // 将姓名写入文件之中 raf.writeInt(age); // 将年龄写入文件之中 name = \"wangwu \"; // 字符串长度为8 age = 32; // 数字的长度为4 raf.writeBytes(name); // 将姓名写入文件之中 raf.writeInt(age); // 将年龄写入文件之中 raf.close(); &#125; public void readFile(String filename) &#123; try (RandomAccessFile raf = new RandomAccessFile(filename, \"rw\");) &#123; raf.skipBytes(12);//跳过12个字节 byte[] bytes = new byte[8]; for (int i = 0; i &lt; bytes.length; i++) &#123; bytes[i] = raf.readByte(); &#125; System.out.println(\"name===\" + new String(bytes, \"utf-8\")); System.out.println(\"age====\" + raf.readInt()); raf.seek(0);//跳到第0个字节的位置 for (int i = 0; i &lt; bytes.length; i++) &#123; bytes[i] = raf.readByte(); &#125; System.out.println(\"name===\" + new String(bytes, \"utf-8\")); System.out.println(\"age====\" + raf.readInt()); raf.skipBytes(12);//跳过12个字节 for (int i = 0; i &lt; bytes.length; i++) &#123; bytes[i] = raf.readByte(); &#125; System.out.println(\"name===\" + new String(bytes, \"utf-8\")); System.out.println(\"age====\" + raf.readInt()); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125; 对比IO流 流向分类差别 普通文件流：分输入流和输出流 随机读写流：既是输入流也是输出流 基本方法区别 普通文件流：拥有所有共性方法， 比如read（），write（），close（），flush（），skip（）等等方法 随机读写流：除了拥有这些共性方法，还有自己特有的方法， 比如readLine（），seek（），skipBytes（）等等方法 特别注意：随机读写流没有flush（）方法 构造方法区别 普通文件流： 1）输入流：参数都文件路径 FileInputStream(File file) FileInputStream(String name) 2）输出流：参数1–都是文件路径； FileOutputStream(File file) FileOutputStream(String name) 参数2 append： true时--写入时不覆盖原有内容，而是在文件内容后面接着写； false--写入时会覆盖原有内容，没有第二个参数时默认是false FileOutputStream(File file, boolean append) FileOutputStream(String name, boolean append) 随机读写流： 参数1：都是文件路径；参数2：是读写模式，只有两个取值--r或rw RandomAccessFile(File file, String mode) RandomAccessFile(String name, String mode) 读写位置区别 普通文件流：只能在指定位置【读取】–skip（）方法，不能指定位置写入 随机文件流：可以在指定位置进行【读写】，使用seek（）方法 应用区别 普通文件流：使用普通文件流不能进行多线程复制 随机读写流：可以进行多线程复制","categories":[{"name":"Java基础","slug":"Java基础","permalink":"http://blog.jackhoo.cn/categories/Java基础/"}],"tags":[{"name":"IO","slug":"IO","permalink":"http://blog.jackhoo.cn/tags/IO/"},{"name":"文件读取","slug":"文件读取","permalink":"http://blog.jackhoo.cn/tags/文件读取/"}]},{"title":"深入理解Java虚拟机有感.md","slug":"深入理解Java虚拟机有感","date":"2017-09-23T19:50:00.000Z","updated":"2018-03-23T17:30:38.853Z","comments":true,"path":"2017/09/24/深入理解Java虚拟机有感/","link":"","permalink":"http://blog.jackhoo.cn/2017/09/24/深入理解Java虚拟机有感/","excerpt":"","text":"深入理解 Java 虚拟机 学习笔记 深入理解 Java 虚拟机 学习笔记 第二章 Java 内存区域与内存溢出异常 内存区域 对象创建 对象的内存布局 对象访问 内存溢出异常 常用 JVM 参数 （Java HotSpot VM） 常见异常及可能原因 String 与字符串常量 第三章 垃圾收集器与内存分配策略 判断对象是否存活 垃圾收集算法 HotSpot 算法实现 垃圾收集器 内存分配与回收策略 第六章 类文件结构 第七章 虚拟机类加载机制 类加载的过程 类加载器 第十章 早期（编译器）优化 前端编译过程（*.java --&gt; *.class） 参考 第二章 Java 内存区域与内存溢出异常内存区域 – from 姜志明 对象创建 加载类 若已经在内存中则跳过。 类加载完以后就可以确定对象所需的空间大小 // TODO why? 分配内存 根据 GC 回收算法的不同，分配方式略有区别。 标记整理算法，使用空闲列表 带压缩的算法，使用指针碰撞（已分配和未分配内存间由指针分隔） 内存清零 对象初始化 对象的内存布局 MarkWord 占用一个 字 的大小，其中分为两部分： 对象自身运行时元数据。例如，哈希码、GC 分代年龄、锁状态标志等等 类型指针。指向其类的元数据。 若对象是数组则还需要保存数组的长度。 域的存储顺序： 基本类型优先，长度长的优先。 父类域优先。子类较短域可插入父类域空隙。 受虚拟机分配策略参数和域定义顺序的影响。 对象访问两种方式： 直接引用 引用句柄（句柄池） 内存溢出异常常用 JVM 参数 （Java HotSpot VM） 参数 含义 实例 -verbose:class 显示每一个被加载的类的信息 -verbose:gc 显示每一个 GC 事件的信息 -Xmnsize 年轻代最大容量 -Xmn256m -Xmssize 堆的初始大小。1024 的整数倍并且要大于 1MB -Xms6m -Xmxsize 堆的最大容量。1024 的整数倍并且要大于 2MB -Xmx80m -Xsssize 线程栈容量。平台不同默认值不同，详情参考文档。Linux/x64 (64-bit): 1024 KB -Xss1m -XX:MaxDirectMemorySize=size 直接内存的最大容量，默认与堆容量相同 -XX:MaxDirectMemorySize=1m -XX:+HeapDumpOnOutOfMemory 当抛出 OOM 时，使用 HPROF 将堆的快照保存到当前目录 -XX:HeapDumpPath=path 设置快照输出路径 -XX:HeapDumpPath=/var/log/java/java_heapdump.hprof -XX:+PrintGCDetails 开启在 GC 时打印详细信息 -XX:SurvivorRatio=ratio 新生代中 eden 与 survivor 的大小比例，默认为 8 -XX:SurvivorRatio=4 参考： Java HotSpot VM 参数 常见异常及可能原因 堆区 OutOfMemoryException。使用工具对快照进行分析，看是否发生了内存泄露（内存中有不再使用的但无法回收的对象或资源）。若是，则通过分析引用链找到根源，解决问题；若不是检查虚拟机堆参数，看是否能够调大。再检查代码中是否有生命周期很长的大对象。 虚拟机栈和本地方法栈 OutOfMemoryException。栈容量 * 线程数量 = 固定值。当线程数量过多时会引发，可以适当减小栈容量。 StackOverflowException。按异常查根源。 方法区和运行时常量池 直接内存溢出 不正确的使用 NIO。 String 与字符串常量12345678910111213141516171819public class StringTest &#123; public static void main(String[] args) &#123; String m = \"hello\"; String n = \"hello\"; String u = new String(m); String v = new String(\"hello\"); System.out.println(\"m == n: \" + (m == n)); System.out.println(\"m == u: \" + (m == u)); System.out.println(\"m == v: \" + (m == v)); System.out.println(\"u == v: \" + (u == v)); &#125;&#125;output:m == n: truem == u: falsem == v: falseu == v: false 参考： 初探Java字符串 第三章 垃圾收集器与内存分配策略判断对象是否存活 引用计数器算法。给对象添加一个引用计数器，增加/删除引用时对计数器进行修订。但是该方法因为无法解决循环引用（例如两个对象互相引用）的问题，所以一般不使用该方法 可达性分析算法。从 GC root 开始递归查询并标记，结束后未被标记的（不可达的）即为可回收的对象。GC root 共有四种： 栈中引用的对象 方法区常量引用的对象 方法区静态域引用的对象 本地方法中 JNI 引用的对象（不太懂） 回收方法区 新生代的回收效率可达到 70% - 95%，而永久代则低的多（性价比太低） 在大量使用反射、动态代理、CGLib 等 ByteCode 框架、动态生成 JSP 以及 OSGi 这类频繁自定义 ClassLoader 的场景都需要虚拟机有卸载类的能力。 垃圾收集算法 标记-清除算法 扫描一遍，标记出需要回收的对象，再扫描将其清除 标记/清除两阶段时间效率都不高，且回收后空间较零碎。 复制算法 将内存分为两块，当一块中内存不足时，将其中所有存活对象复制到另一块中，回收当前一整块。 目前商用虚拟机大都使用这一算法回收新生代。将内存划分为一个较大的 Eden 区和两块较小的 Survivor. Eden：Survivor = 8：1 标记整理算法 标记出须清理的对象，然后其余对象移动到一端 分代收集算法 新生代使用复制算法 永久代使用其他两种算法 HotSpot 算法实现 当程序执行到安全点（safepoint）时进行 GC，通过在安全点（safepoint）生成的 OopMaps 快速遍历 GC root 进行回收。 安全点（safepoint）：指令序列复用的位置。例如方法调用、循环结构、异常跳转等位置。 OopMaps：一种特殊的数据结构，用于枚举 GC root 但是如果线程处于不执行的状态时，如 sleep 或 blocked 无法执行到安全点，即需要提前标记为安全区域(safe region)。GC 时不考虑处于安全区域的线程，若安全区域代码执行结束但 GC 未结束时该线程等待 GC 结束信号。 安全区域（safe region）：引用不发生改变的代码片段 垃圾收集器 并发(concurrent) vs 并行(parallel) 并行是同时进行（多 CPU） 并发可交替 Minor GC vs Major GC vs Full GC Minor GC：只回收新生代 Major GC：只回收永久代 Full GC： 回收整个堆。相当于 Minor GC + Major GC serial。单线程，简单高效。复制算法 PerNew。serial 的多线程版本，并行。 parallel Scavenge。 与 PerNew 类似，复制算法、多线程、并行。但侧重吞吐量，拥有自适应调节的能力。适合用在后台不需要太多用户交互的地方。 吞吐量 = 用户代码执行时间 / （用户代码执行时间 + 垃圾回收时间） 自适应调节：虚拟机根据但前系统的运行情况，自动调节虚拟机各参数以确保最大吞吐量。 serial old。serial 的永久代版本。采用标记整理算法。 parallel old。parallel Scavenge 的老年代版本，采用标记整理算法。与 parallel scavenge 搭配可以用在注重吞吐量及 CPU 资源敏感的地方。 CMS（concurrent mark sweep）。并发低停顿，使用标记清理算法。非常优秀的一款收集器，但还是有几个缺点： 对 CPU 资源敏感，当其小于数量小于 4 个是可能会对用户程序有较大影响。默认启动回收线程数 = （CPU 数 + 3）/ 4 无法处理浮动垃圾。浮动垃圾：在垃圾回收期间生成的垃圾 回收后会留有大量的空间碎片。 G1 //TODO 内存分配与回收策略TLAB（Thread local allocate buffer）线程私有分配缓冲区，每个线程一个 对象优先在 Eden 区分配。内存不足时触发 Minor GC。 大对象直接进入老年代。例如数组或超过参数指定大小的对象。 长期存活的对象进入老年代。GC 超过一定次数仍存活的对象。默认为 15 次，可通过虚拟机参数 -XX:MaxTenuringThreshold 来设置。 动态对象年龄判定。当一个年龄的所有对象大小总和超过 Servivor 空间一半时，大于等于该年龄的所有对象都进入老年代 空间分配担保。当发生 Minor GC 时，若存活的对象过多，servivor 空间无法全部容纳时，会将剩余的对象直接放入永久代；若永久代空间不足以容纳时会引发一次 Full GC 第六章 类文件结构 类文件的结构拥有固定的格式，包含两部分的数据： 类的元数据。 方法代码的字节流 code 属性表包含的属性 max_stack 存储操作数栈的最大深度值。运行时用来确定分配栈帧中所需的操作数栈深度。 max_locals 局部变量所需的最大空间大小 符号引用 类与接口的全限定名 域的名称与描述符 方法名与描述符 该部分内容可以通过查表获得，不再赘述。 第七章 虚拟机类加载机制类加载的过程 加载 通过全类名获取该类的二进制字节流 解析字节流，将字节流所表达的静态存储结构转化为方法区的运行时数据结构 （这是什么东西？） 为该类创建一个 Class 对象，用来访问该类的类数据 连接 验证 为了确保加载的字节流时符合规范的，不会危害到虚拟机自身的安全。主要包括 文件格式验证 元数据验证 字节码验证 符号引用验证 准备 为类变量分配内存并进行初步初始化（0/null） // 不应该是在类加载阶段完成的么？ 解析 将符号引用替换为直接引用 初始化 static fields and block init 使用 卸载 类加载器 一个加载器确定一个类的命名空间。同一个类由不同加载器加载后是不同的类。 双亲委派：当需要加载一个类时先使用父类加载器（其实这个地方不是很准确，父子关系是通过复合来实现的），若失败了，再使用当前的加载器。如果自己写一个 Object 类，编译可通过但是由于双亲委派，它永远都不会被加载。 第十章 早期（编译器）优化// TODO: 因本章含有相当多的编译原理相关概念，所以第十、十一章学习延后（预计第 8-9 周） 前端编译过程（*.java --&gt; *.class） 解析与填充符号表 词法分析。将源代码转换为标记（Token） 的集合 Token: 是编译过程中的最小元素。例如关键字、变量名、运算符等等 语法分析。通过 Token 序列将构造抽象语法树(Abstract syntax tree) 参考 初探Java字符串 (非常好的一篇文章) Java HotSpot VM 参数 Java HotSpot Virtual Machine Garbage Collection Tuning Guide JVM 垃圾回收器工作原理及使用实例介绍 – IBM Minor GC vs Major GC vs Full GC Abstract syntax tree 4.4 Symbol Tables","categories":[{"name":"Java虚拟机","slug":"Java虚拟机","permalink":"http://blog.jackhoo.cn/categories/Java虚拟机/"}],"tags":[{"name":"Java基础","slug":"Java基础","permalink":"http://blog.jackhoo.cn/tags/Java基础/"},{"name":"Java虚拟机","slug":"Java虚拟机","permalink":"http://blog.jackhoo.cn/tags/Java虚拟机/"}]},{"title":"Tomcat架构及启动过程[含部署]","slug":"Tomcat 架构及启动过程","date":"2017-09-06T08:48:32.000Z","updated":"2018-03-22T16:50:58.026Z","comments":true,"path":"2017/09/06/Tomcat 架构及启动过程/","link":"","permalink":"http://blog.jackhoo.cn/2017/09/06/Tomcat 架构及启动过程/","excerpt":"","text":"Overview Bootstrap 作为 Tomcat 对外界的启动类,在 $CATALINA_BASE/bin 目录下，它通过反射创建 Catalina 的实例并对其进行初始化及启动。 Catalina 解析 $CATALINA_BASE/conf/server.xml 文件并创建 StandardServer、StandardService、StandardEngine、StandardHost 等 StandardServer 代表的是整个 Servlet 容器，他包含一个或多个 StandardService StandardService 包含一个或多个 Connector，和一个 Engine，Connector 和 Engine 都是在解析 conf/server.xml 文件时创建的，Engine 在 Tomcat 的标准实现是 StandardEngine MapperListener 实现了 LifecycleListener 和 ContainerListener 接口用于监听容器事件和生命周期事件。该监听器实例监听所有的容器，包括 StandardEngine、StandardHost、StandardContext、StandardWrapper，当容器有变动时，注册容器到 Mapper。 Mapper 维护了 URL 到容器的映射关系。当请求到来时会根据 Mapper 中的映射信息决定将请求映射到哪一个 Host、Context、Wrapper。 Http11NioProtocol 用于处理 HTTP/1.1 的请求 NioEndpoint 是连接的端点，在请求处理流程中该类是核心类，会重点介绍。 CoyoteAdapter 用于将请求从 Connctor 交给 Container 处理。使 Connctor 和 Container 解耦。 StandardEngine 代表的是 Servlet 引擎，用于处理 Connector 接受的 Request。包含一个或多个 Host（虚拟主机）, Host 的标准实现是 StandardHost。 StandardHost 代表的是虚拟主机，用于部署该虚拟主机上的应用程序。通常包含多个 Context (Context 在 Tomcat 中代表应用程序)。Context 在 Tomcat 中的标准实现是 StandardContext。 StandardContext 代表一个独立的应用程序，通常包含多个 Wrapper，一个 Wrapper 容器封装了一个 Servlet，Wrapper 的标准实现是 StandardWrapper。 StandardPipeline 组件代表一个流水线，与 Valve（阀）结合，用于处理请求。 StandardPipeline 中含有多个 Valve， 当需要处理请求时，会逐一调用 Valve 的 invoke 方法对 Request 和 Response 进行处理。特别的，其中有一个特殊的 Valve 叫 basicValve,每一个标准容器都有一个指定的 BasicValve，他们做的是最核心的工作。 StandardEngine 的是 StandardEngineValve，他用来将 Request 映射到指定的 Host; StandardHost 的是 StandardHostValve, 他用来将 Request 映射到指定的 Context; StandardContext 的是 StandardContextValve，它用来将 Request 映射到指定的 Wrapper； StandardWrapper 的是 StandardWrapperValve，他用来加载 Rquest 所指定的 Servlet,并调用 Servlet 的 Service 方法。 Tomcat init 当通过 ./startup.sh 脚本或直接通过 java 命令来启动 Bootstrap 时，Tomcat 的启动过程就正式开始了，启动的入口点就是 Bootstrap 类的 main 方法。 启动的过程分为两步，分别是 init 和 start，本节主要介绍 init; 初始化类加载器。[关于 Tomcat 类加载机制，可以参考我之前写的一片文章：谈谈Java类加载机制] 通过从 CatalinaProperties 类中获取 common.loader 等属性，获得类加载器的扫描仓库。CatalinaProperties 类在的静态块中调用了 loadProperties() 方法，从 conf/catalina.properties 文件中加载了属性.(即在类创建的时候属性就已经加载好了)。 通过 ClassLoaderFactory 创建 URLClassLoader 的实例 通过反射创建 Catalina 的实例并设置 parentClassLoader setAwait(true)。设置 Catalina 的 await 属性为 true。在 Start 阶段尾部，若该属性为 true，Tomcat 会在 main 线程中监听 SHUTDOWN 命令，默认端口是 8005.当收到该命令后执行 Catalina 的 stop() 方法关闭 Tomcat 服务器。 createStartDigester()。Catalina 的该方法用于创建一个 Digester 实例，并添加解析 conf/server.xml 的 RuleSet。Digester 原本是 Apache 的一个开源项目，专门解析 XML 文件的，但我看 Tomcat-9.0.0.M22 中直接将这些类整合到 Tomcat 内部了，而不是引入 jar 文件。Digester 工具的原理不在本文的介绍范围，有兴趣的话可以参考 The Digester Component - Apache 或 《How Tomcat works》- Digester [推荐] 一章 parse() 方法就是 Digester 处理 conf/server.xml 创建各个组件的过程。值的一提的是这些组件都是使用反射的方式来创建的。特别的，在创建 Digester 的时候，添加了一些特别的 rule Set，用于创建一些十分核心的组件，这些组件在 conf/server.xml 中没有但是其作用都比较大，这里做下简单介绍，当 Start 时用到了再详细说明： EngineConfig。LifecycleListener 的实现类,触发 Engine 的生命周期事件后调用，这个监听器没有特别大的作用，就是打印一下日志 HostConfig。LifecycleListener 的实现类，触发 Host 的生命周期事件后调用。这个监听器的作用就是部署应用程序，这包括 conf/&lt;Engine&gt;/&lt;Host&gt;/ 目录下所有的 Context xml 文件 和 webapps 目录下的应用程序，不管是 war 文件还是已解压的目录。另外后台进程对应用程序的热部署也是由该监听器负责的。 ContextConfig。LifecycleListener 的实现类，触发 Context 的生命周期事件时调用。这个监听器的作用是配置应用程序，它会读取并合并 conf/web.xml 和 应用程序的 web.xml，分析 /WEB-INF/classes/ 和 /WEB-INF/lib/*.jar 中的 Class 文件的注解，将其中所有的 Servlet、ServletMapping、Filter、FilterMapping、Listener 都配置到 StandardContext 中，以备后期使用。当然了 web.xml 中还有一些其他的应用程序参数，最后都会一并配置到 StandardContext 中。 reconfigureStartStopExecutor() 用于重新配置启动和停止子容器的 Executor。默认是 1 个线程。我们可以配置 conf/server.xml 中 Engine 的 startStopThreads，来指定用于启动和停止子容器的线程数量，如果配置 0 的话会使用 Runtime.getRuntime().availableProcessors() 作为线程数，若配置为负数的话会使用 Runtime.getRuntime().availableProcessors() + 配置值，若和小与 1 的话，使用 1 作为线程数。当线程数是 1 时，使用 InlineExecutorService 它直接使用当前线程来执行启动停止操作，否则使用 ThreadPoolExecutor 来执行，其最大线程数为我们配置的值。 需要注意的是 Host 的 init 操作是在 Start 阶段来做的， StardardHost 创建好后其 state 属性的默认值是 LifecycleState.NEW，所以在其调用 startInternal() 之前会进行一次初始化。 Tomcat Start[Deployment] 图中从 StandardHost Start StandardContext 的这步其实在真正的执行流程中会直接跳过，因为 conf/server.xml 文件中并没有配置任何的 Context，所以在 findChildren() 查找子容器时会返回空数组，所以之后遍历子容器来启动子容器的 for 循环就直接跳过了。 触发 Host 的 BEFORE_START_EVENT 生命周期事件，HostConfig 调用其 beforeStart() 方法创建 $CATALINA_BASE/webapps &amp; $CATALINA_BASE/conf/&lt;Engine&gt;/&lt;Host&gt;/ 目录。 触发 Host 的 START_EVENT 生命周期事件，HostConfig 调用其 start() 方法开始部署已在 $CATALINA_BASE/webapps &amp; $CATALINA_BASE/conf/&lt;Engine&gt;/&lt;Host&gt;/ 目录下的应用程序。 解析 $CATALINA_BASE/conf/&lt;Engine&gt;/&lt;Host&gt;/ 目录下所有定义 Context 的 XML 文件，并添加到 StandardHost。这些 XML 文件称为应用程序描述符。正因为如此，我们可以配置一个虚拟路径来保存应用程序中用到的图片，详细的配置过程请参考 开发环境配置指南 - 6.3. 配置图片存放目录 部署 $CATALINA_BASE/webapps 下所有的 WAR 文件，并添加到 StandardHost。 部署 $CATALINA_BASE/webapps 下所有已解压的目录，并添加到 StandardHost。 特别的，添加到 StandardHost 时，会直接调用 StandardContext 的 start() 方法来启动应用程序。启动应用程序步骤请看 Context Start 一节。 在 StandardEngine 和 StandardContext 启动时都会调用各自的 threadStart() 方法，该方法会创建一个新的后台线程来处理该该容器和子容器及容器内各组件的后台事件。StandardEngine 会直接创建一个后台线程，StandardContext 默认是不创建的，和 StandardEngine 共用同一个。后台线程处理机制是周期调用组件的 backgroundProcess() 方法。详情请看 Background process 一节。 MapperListener addListeners(engine) 方法会将该监听器添加到 StandardEngine 和它的所有子容器中 registerHost() 会注册所有的 Host 和他们的子容器到 Mapper 中，方便后期请求处理时使用。 当有新的应用(StandardContext)添加进来后，会触发 Host 的容器事件，然后通过 MapperListener 将新应用的映射注册到 Mapper 中。 Start 工作都做完以后 Catalina 会创建一个 CatalinaShutdownHook 并注册到 JVM。CatalinaShutdownHook 继承了 Thread,是 Catalina 的内部类。其 run 方法中直接调用了 Catalina 的 stop() 方法来关闭整个服务器。注册该 Thread 到 JVM 的原因是防止用户非正常终止 Tomcat，比如直接关闭命令窗口之类的。当直接关闭命令窗口时，操作系统会向 JVM 发送一个终止信号，然后 JVM 在退出前会逐一启动已注册的 ShutdownHook 来关闭相应资源。 Context Start StandRoot 类实现了 WebResourceRoot 接口，它容纳了一个应用程序的所有资源，通俗的来说就是部署到 webapps 目录下对应 Context 的目录里的所有资源。因为我对 Tomcat 的资源管理部分暂时不是很感兴趣，所以资源管理相关类只是做了简单了解，并没有深入研究源代码。 resourceStart() 方法会对 StandardRoot 进行初始配置 postWorkDirectory() 用于创建对应的工作目录 $CATALINA_BASE/work/&lt;Engine&gt;/&lt;Host&gt;/&lt;Context&gt;, 该目录用于存放临时文件。 StardardContext 只是一个容器，而 ApplicationContext 则是一个应用程序真正的运行环境，相关类及操作会在请求处理流程看完以后进行补充。 StardardContext 触发 CONFIGURE_START_EVENT 生命周期事件，ContextConfig 开始调用 configureStart() 对应用程序进行配置。 这个过程会解析并合并 conf/web.xml &amp; conf/&lt;Engine&gt;/&lt;Host&gt;/web.xml.default &amp; webapps/&lt;Context&gt;/WEB-INF/web.xml 中的配置。 配置配置文件中的参数到 StandardContext, 其中主要的包括 Servlet、Filter、Listener。 因为从 Servlet3.0 以后是直接支持注解的，所以服务器必须能够处理加了注解的类。Tomcat 通过分析 WEB-INF/classes/ 中的 Class 文件和 WEB-INF/lib/ 下的 jar 包将扫描到的 Servlet、Filter、Listerner 注册到 StandardContext。 setConfigured(true)，是非常关键的一个操作，它标识了 Context 的成功配置，若未设置该值为 true 的话，Context 会启动失败。 Background process 后台进程的作用就是处理一下 Servlet 引擎中的周期性事件，处理周期默认是 10s。 特别的 StandardHost 的 backgroundProcess() 方法会触发 Host 的 PERIODIC_EVENT 生命周期事件。然后 HostConfig 会调用其 check() 方法对已加载并进行过重新部署的应用程序进行 reload 或对新部署的应用程序进行热部署。热部署跟之前介绍的部署步骤一致， reload() 过程只是简单的顺序调用 setPause(true)、stop()、start()、setPause(false)，其中 setPause(true) 的作用是暂时停止接受请求。 Reference 《How Tomcat works》 《Tomcat 架构解析》– 刘光瑞 Tomcat-9.0-doc apache-tomcat-9.0.0.M22-src","categories":[{"name":"Tomcat","slug":"Tomcat","permalink":"http://blog.jackhoo.cn/categories/Tomcat/"}],"tags":[{"name":"tomcat","slug":"tomcat","permalink":"http://blog.jackhoo.cn/tags/tomcat/"}]},{"title":"Tomcat请求处理流程","slug":"Tomcat请求处理流程","date":"2017-09-05T08:48:32.000Z","updated":"2018-03-23T16:48:06.083Z","comments":true,"path":"2017/09/05/Tomcat请求处理流程/","link":"","permalink":"http://blog.jackhoo.cn/2017/09/05/Tomcat请求处理流程/","excerpt":"","text":"Tomcat 请求处理流程Overview Connector 启动以后会启动一组线程用于不同阶段的请求处理过程。 Acceptor 线程组。用于接受新连接，并将新连接封装一下，选择一个 Poller 将新连接添加到 Poller 的事件队列中。 Poller 线程组。用于监听 Socket 事件，当 Socket 可读或可写等等时，将 Socket 封装一下添加到 worker 线程池的任务队列中。 worker 线程组。用于对请求进行处理，包括分析请求报文并创建 Request 对象，调用容器的 pipeline 进行处理。 Acceptor、Poller、worker 所在的 ThreadPoolExecutor 都维护在 NioEndpoint 中。 Connector Init and Start initServerSocket()，通过 ServerSocketChannel.open() 打开一个 ServerSocket，默认绑定到 8080 端口，默认的连接等待队列长度是 100， 当超过 100 个时会拒绝服务。我们可以通过配置 conf/server.xml 中 Connector 的 acceptCount 属性对其进行定制。 createExecutor() 用于创建 Worker 线程池。默认会启动 10 个 Worker 线程，Tomcat 处理请求过程中，Woker 最多不超过 200 个。我们可以通过配置 conf/server.xml 中 Connector 的 minSpareThreads 和 maxThreads 对这两个属性进行定制。 Pollor 用于检测已就绪的 Socket。 默认最多不超过 2 个，Math.min(2,Runtime.getRuntime().availableProcessors());。我们可以通过配置 pollerThreadCount 来定制。 Acceptor 用于接受新连接。默认是 1 个。我们可以通过配置 acceptorThreadCount 对其进行定制。 Requtst ProcessAcceptor Acceptor 在启动后会阻塞在 ServerSocketChannel.accept(); 方法处，当有新连接到达时，该方法返回一个 SocketChannel。 配置完 Socket 以后将 Socket 封装到 NioChannel 中，并注册到 Poller,值的一提的是，我们一开始就启动了多个 Poller 线程，注册的时候，连接是公平的分配到每个 Poller 的。NioEndpoint 维护了一个 Poller 数组，当一个连接分配给 pollers[index] 时，下一个连接就会分配给 pollers[(index+1)%pollers.length]. addEvent() 方法会将 Socket 添加到该 Poller 的 PollerEvent 队列中。到此 Acceptor 的任务就完成了。 Poller selector.select(1000)。当 Poller 启动后因为 selector 中并没有已注册的 Channel，所以当执行到该方法时只能阻塞。所有的 Poller 共用一个 Selector，其实现类是 sun.nio.ch.EPollSelectorImpl events() 方法会将通过 addEvent() 方法添加到事件队列中的 Socket 注册到 EPollSelectorImpl，当 Socket 可读时，Poller 才对其进行处理 createSocketProcessor() 方法将 Socket 封装到 SocketProcessor 中，SocketProcessor 实现了 Runnable 接口。worker 线程通过调用其 run() 方法来对 Socket 进行处理。 execute(SocketProcessor) 方法将 SocketProcessor 提交到线程池，放入线程池的 workQueue 中。workQueue 是 BlockingQueue 的实例。到此 Poller 的任务就完成了。 Worker worker 线程被创建以后就执行 ThreadPoolExecutor 的 runWorker() 方法，试图从 workQueue 中取待处理任务，但是一开始 workQueue 是空的，所以 worker 线程会阻塞在 workQueue.take() 方法。 当新任务添加到 workQueue后，workQueue.take() 方法会返回一个 Runnable，通常是 SocketProcessor,然后 worker 线程调用 SocketProcessor 的 run() 方法对 Socket 进行处理。 createProcessor() 会创建一个 Http11Processor, 它用来解析 Socket，将 Socket 中的内容封装到 Request 中。注意这个 Request 是临时使用的一个类，它的全类名是 org.apache.coyote.Request， postParseRequest() 方法封装一下 Request，并处理一下映射关系(从 URL 映射到相应的 Host、Context、Wrapper)。 CoyoteAdapter 将 Rquest 提交给 Container 处理之前，并将 org.apache.coyote.Request 封装到 org.apache.catalina.connector.Request，传递给 Container 处理的 Request 是 org.apache.catalina.connector.Request。 connector.getService().getMapper().map()，用来在 Mapper 中查询 URL 的映射关系。映射关系会保留到 org.apache.catalina.connector.Request 中，Container 处理阶段 request.getHost() 是使用的就是这个阶段查询到的映射主机，以此类推 request.getContext()、request.getWrapper() 都是。 connector.getService().getContainer().getPipeline().getFirst().invoke() 会将请求传递到 Container 处理，当然了 Container 处理也是在 Worker 线程中执行的，但是这是一个相对独立的模块，所以单独分出来一节。 Container 需要注意的是，基本上每一个容器的 StandardPipeline 上都会有多个已注册的 Valve，我们只关注每个容器的 Basic Valve。其他 Valve 都是在 Basic Valve 前执行。 request.getHost().getPipeline().getFirst().invoke() 先获取对应的 StandardHost，并执行其 pipeline。 request.getContext().getPipeline().getFirst().invoke() 先获取对应的 StandardContext,并执行其 pipeline。 request.getWrapper().getPipeline().getFirst().invoke() 先获取对应的 StandardWrapper，并执行其 pipeline。 最值得说的就是 StandardWrapper 的 Basic Valve，StandardWrapperValve allocate() 用来加载并初始化 Servlet，值的一提的是 Servlet 并不都是单例的，当 Servlet 实现了 SingleThreadModel 接口后，StandardWrapper 会维护一组 Servlet 实例，这是享元模式。当然了 SingleThreadModel 在 Servlet 2.4 以后就弃用了。 createFilterChain() 方法会从 StandardContext 中获取到所有的过滤器，然后将匹配 Request URL 的所有过滤器挑选出来添加到 filterChain 中。 doFilter() 执行过滤链,当所有的过滤器都执行完毕后调用 Servlet 的 service() 方法。","categories":[{"name":"Tomcat","slug":"Tomcat","permalink":"http://blog.jackhoo.cn/categories/Tomcat/"}],"tags":[{"name":"tomcat","slug":"tomcat","permalink":"http://blog.jackhoo.cn/tags/tomcat/"}]},{"title":"Java计算常用类BigDecimal","slug":"Java计算常用类BigDecimal","date":"2017-08-01T16:50:00.000Z","updated":"2018-03-23T17:25:22.117Z","comments":true,"path":"2017/08/02/Java计算常用类BigDecimal/","link":"","permalink":"http://blog.jackhoo.cn/2017/08/02/Java计算常用类BigDecimal/","excerpt":"","text":"java.lang.BigDecimal基于 JDK9 概览 继承结构 Number 重要相关类 RoundingMode MathContext BigInteger 重要域成员 重要成员方法 算数操作 缩放 最佳实践 参考 概览不可变的任意精度有符号十进制数。 BigDecimal 用一个任意精度整数和一个缩放比例来表示一个数。精度是从左侧第一个非 0 数字开始到最后一个数字为止的数字个数。一些例子： 表示的数 精度 整数域 缩放比例 计算方式 100 3 100 0 100*(E-0) 0.01 1 1 2 1*(E-2) 100.001 6 100001 3 100001*(E-3) 100000000000000000000.01 22 1000000000000000000001 2 1000000000000000000001*(E-2) 注意：缩放比例一般是非负数（整数是 0，小数是正数，当计算结果的整数部分位数大于精度时会是负数），缩放比例也可以手动调用 setScale() 方法修改为负数，缩放比例为负数时意味着小数点前移，有可能会损失精度（比如：109，本来整数域是 109、缩放比例是 0，若缩放比例改为 -1 的话，整数域就需要变为 10 或 11，而这两种方式都无法准确表示原来的 109）。在调用 setScale() 时需要指定舍入策略，否则整数域无法判断是记为 10 还是 11，demo 请看 重要成员方法-setScale()。 BigDecimal 提供了一些算数、缩放、舍入、比较、哈希、格式转换操作。 toString() 方式提供了一种规范的展示方式(PS：IDEA 在显示 debug 信息时会调用对象的 toString() 方法。如果在实例真正的创建完成之前加断点停住了，那么这个 BigDecimal 实例就永远也得不到正确的 String 方式的展示了。 BigDecimal 把舍入行为的控制权完全交给了使用者。如果未指定舍入模式并且计算结果无法被精确记录会直接抛出一个 ArithmeticException。若在计算时指定了 MathContext，那么结果会以 MathContext 所定义的精度和舍入规则来保留。 12345678BigDecimal one = BigDecimal.ONE;BigDecimal three = new BigDecimal(\"3\");BigDecimal result = one.divide(three); // 1/3 是无限循环小数，所以会抛异常BigDecimal result = one.divide(three, RoundingMode.UP); // 1BigDecimal result = one.divide(three, new MathContext(7, RoundingMode.HALF_UP)); // 0.3333333 当指定的 MathContext 实例的精度是 0 时，和未指定该参数的效果是一样的，此时 MathContext 中的 RoundingMode 并未使用，所以结果与该值无关。 通常来说，舍入策略和精度决定了计算结果。精度决定计算结果的数字个数，舍入策略决定了如何舍弃尾部的数字。 算数操作结果的缩放比例，除运算可能会使用更大的缩放比例，其他的运算遵循表格中的计算方式： 比如 123BigDecimal dividend = BigDecimal.ONE; // scale : 0BigDecimal divisor = new BigDecimal(\"32\"); // scale : 0BigDecimal result = dividend.divide(divisor); // scale : 5 算数操作会先计算出一个中间结果（逻辑上的，实际本不存在这个实例），然后根据舍入规则和精度对该中间结果进行再次处理，得到的才是最后的结果。 注意：equal() &amp; hashCode() 方法在实现时，只有缩放比例和整数域两个值都相等才会判定两个实例相等，所以将 BigDecimal 的实例做为 SortedMap &amp; SortSet 的 key时需要注意这一点 继承结构 Number该类是一个抽象类，是 Java 平台所有数字类的父类。它提供了一些抽象方法接口将数字类转换为各种基本数据类型。这些方法由具体的数字类来实现。转换的过程可能会丢失精度、甚至改变符号。 一些子类：AtomicInteger, AtomicLong, BigDecimal, BigInteger, Byte, Double, DoubleAccumulator, DoubleAdder, Float, Integer, Long, LongAccumulator, LongAdder, Short 重要相关类RoundingMode该类是一个枚举类，枚举了 8 种舍入类型： CEILING。向正无穷舍入 FLOOR。向负无穷舍入 DOWN。向 0 舍入 UP。与 DOWN 相反。 HALF_UP。五入 HALF_DOWN。五舍 HALF_EVEN。五向偶数方向舍入。 UNNECESSARY。表示一定会得到精确结果，得不到时抛异常。 MathContext封装了精度及舍入规则，用于算数运算。 预定义的一些规则： 123456789101112131415//精度为 0，相当于没有配置public static final MathContext UNLIMITED = new MathContext(0, RoundingMode.HALF_UP);// 精度为 7，舍入策略为 HALF_EVENpublic static final MathContext DECIMAL32 = new MathContext(7, RoundingMode.HALF_EVEN);// 精度为 16，舍入策略为 HALF_EVENpublic static final MathContext DECIMAL64 = new MathContext(16, RoundingMode.HALF_EVEN);// 精度为 34，舍入策略为 HALF_EVENpublic static final MathContext DECIMAL128 = new MathContext(34, RoundingMode.HALF_EVEN); BigInteger任意精度的整数。底层存储方式也是 bits 位，与基本类型的区别在于，基本类型 int 固定 32bits，BigInteger 的 bits 存储在一个 int[] 中，所以他可以表示很大的整数。比如 2^128 的二进制表示是 100...000(1+128个0) 一共 129 位，存放在长度为 Math.ceil(129.0/32) 的数组中。不再赘述，有兴趣自己查看源码。 重要域成员 private final BigInteger intVal; 整数域。(整数域超过 18 位时使用) private final transient long intCompact; 整数域。整数域在 long 能够表示的范围内使用，超出能表示范围会被赋为 Long.MIN_VALUE，代表整数域此时使用 intVal 来表示 private final int scale; 缩放比例。也代表小数点右侧的数字数，整数域相同，缩放比例越大表示的数越小。 private transient int precision; 精度。代表从左侧第一个非 0 数字开始到最后一个数字为止的数字个数。 precision - scale 值为正数时代表整数部分的位数。负数时表示小数点右侧 0 的个数且该数小于 1。 private transient String stringCache; String 表示的缓存。该值只赋值一次。 预缓存的 BigDecimal public static final BigDecimal ZERO public static final BigDecimal ONE public static final BigDecimal TEN 重要成员方法为了简化描述方式下面使用 [整数域，缩放比例] 来表示 BigDecimal 实例。例如 0.19 --&gt; [19（整数域）, 2（缩放比例）, 2（精度，可选）] 来表示，中间结果只是逻辑上存在，实际上并不存在这个实例。 算数操作 Add [19, 2] + [19, 2] = [38, 2] [19, 2] + [19, 1] = [19, 2] + [190, 2] = [209, 2] Subtract [19, 2] - [10, 2] = [19, 2] + [-10, 2] = [9, 2] multiply [1, 2] * [3, 4] = [3(1*3), 6(2+4)] divide divide(BigDecimal): [19, 2] / [100, 0] = [19*E+12, 14] / [100, 0] = [19*E+10, 14] = [19, 4] 此时未指定特定的 MathContext, 所以使用了默认值 new MathContext( (int)Math.min(this.precision() + (long)Math.ceil(10.0*divisor.precision()/3.0), Integer.MAX_VALUE), RoundingMode.UNNECESSARY); 即精度为 2+10*3/3 = 12，舍入方法为 UNNECESSARY 14 = MathContext.precision + preferredScale = 12 + 2 - 0 化简一下得到最后结果 其他运算有兴趣可以自己看源码。 缩放BigDecimal 提供了两种类型的方法来操作缩放比例。 setScale() &amp; round()。返回一个与原来实例近似或完全相等的实例，只是缩放比例或精度为指定的值(精度=缩放比例+整数部分位数，当 BigDecimal 整数部分为 0 时，调整缩放比例就是调整精度)。 setScale(1, RoundingMode.UP): [19, 2] -&gt; [2, 1] setScale(3): [19, 2] -&gt; [190, 3] round(mc(1, RoundingMode.UP)): [19, 2, 2] -&gt; [2, 1, 1] round(mc(3, RoundingMode.UNNECESSARY)) : [19, 2, 2] -&gt; [190, 3, 3] movePointLeft() &amp; movePointRight()。直接增大/减小缩放比例。 movePointLeft(1): [19, 2] -&gt; [19, 3] movePointright(1): [19, 2] -&gt; [19, 1] 最佳实践 使用参数为 String 的构造参数。javadoc 中提到使用参数为 double 的构造参数有时会有出现不可预料的问题。 比较时使用 compareTo() / signum() 方法。概览中最后有提到不使用 equals() 的原因。 目前能想到的就这么多，如果你有其他想法可以给我提 issue 参考 Class BigDecimal Setting scale to a negative number with BigDecimal – stackoverflow Class Number Enum RoundingMode Class MathContext Class BigInteger How to Use Java BigDecimal: A Tutorial","categories":[{"name":"Java基础","slug":"Java基础","permalink":"http://blog.jackhoo.cn/categories/Java基础/"}],"tags":[{"name":"java","slug":"java","permalink":"http://blog.jackhoo.cn/tags/java/"},{"name":"BigDecimal","slug":"BigDecimal","permalink":"http://blog.jackhoo.cn/tags/BigDecimal/"}]},{"title":"Servlet配置过滤器和异步过滤器","slug":"Servlet配置过滤器和异步过滤器","date":"2017-06-24T05:39:00.000Z","updated":"2018-03-23T17:43:04.261Z","comments":true,"path":"2017/06/24/Servlet配置过滤器和异步过滤器/","link":"","permalink":"http://blog.jackhoo.cn/2017/06/24/Servlet配置过滤器和异步过滤器/","excerpt":"","text":"1.过滤器的实现。12345678910111213141516171819202122232425262728293031323334public class RequestLogFilter implements Filter&#123; @Override public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException &#123; Instant time = Instant.now(); StopWatch timer = new StopWatch(); try &#123; timer.start(); chain.doFilter(request, response); &#125; finally &#123; timer.stop(); HttpServletRequest in = (HttpServletRequest)request; HttpServletResponse out = (HttpServletResponse)response; String length = out.getHeader(\"Content-Length\"); if(length == null || length.length() == 0) length = \"-\"; System.out.println(in.getRemoteAddr() + \" - - [\" + time + \"]\" + \" \\\"\" + in.getMethod() + \" \" + in.getRequestURI() + \" \" + in.getProtocol() + \"\\\" \" + out.getStatus() + \" \" + length + \" \" + timer); &#125; &#125; @Override public void init(FilterConfig filterConfig) throws ServletException &#123; &#125; @Override public void destroy() &#123; &#125;&#125; 2.部署过滤器。","categories":[{"name":"Servlet","slug":"Servlet","permalink":"http://blog.jackhoo.cn/categories/Servlet/"}],"tags":[{"name":"servlet","slug":"servlet","permalink":"http://blog.jackhoo.cn/tags/servlet/"},{"name":"过滤器","slug":"过滤器","permalink":"http://blog.jackhoo.cn/tags/过滤器/"}]},{"title":"SpringBoot+Vue+Nginx打造自己的直播间","slug":"SpringBoot+Vue+Nginx打造自己的直播间","date":"2017-06-23T17:32:00.000Z","updated":"2018-03-23T17:35:45.325Z","comments":true,"path":"2017/06/24/SpringBoot+Vue+Nginx打造自己的直播间/","link":"","permalink":"http://blog.jackhoo.cn/2017/06/24/SpringBoot+Vue+Nginx打造自己的直播间/","excerpt":"","text":"最终成果 演示地址(电脑端与移动端效果不同哦) 服务端项目地址 客户端项目地址 手机端效果![动图][1] 这个场景很熟悉吧~~ 通过obs推流软件来推流。 ![图片描述][2] 户外直播，通过yasea手机端推流软件，使用手机摄像头推流。 ![图片描述][3] 电脑端效果播放香港卫视 ![图片描述][4] 直播画面 ![图片描述][5] 项目总览项目分为三个部分: 客户端直播间视频拉流、播放和聊天室，炫酷的弹幕以及直播间信息 服务端处理直播间、用户的数据业务,聊天室消息的处理 服务器部署视频服务器和web服务器 技术栈移动客户端 VUE全家桶 UI层vonic axios 视频播放器: vue-video-player + videojs-contrib-hls websocket客户端: vue-stomp 弹幕插件: vue-barrage 打包工具:webpack 电脑端客户端 项目架构: Jquery + BootStrap 视频播放器: video.js websocket客户端: stomp.js + sockjs.js 弹幕插件: Jquery.danmu.js 模版引擎: thymeleaf 服务端 IDE: IntelliJ IDEA 项目架构: SpringBoot1.5.4 +Maven3.0 主数据库: Mysql5.7 辅数据库: redis3.2 数据库访问层: spring-boot-starter-data-jpa + spring-boot-starter-data-redis websocket: spring-boot-starter-websocket 消息中间件: RabbitMQ/3.6.10 服务器部署 视频直播模块: nginx-rtmp-module web应用服务器: tomcat8.0 服务器: 腾讯云centos6.5 技术点讲解 ###直播间主要涉及到两个主要功能：第一是视频直播、第二是聊天室。这两个都是非常讲究实时性。 视频直播 说到直播我们先了解下几个常用的直播流协议,看了挺多的流媒体协议文章博客，但都是非常粗略，这里有个比较详细的 流媒体协议介绍，如果想详细了解协议内容估计去要看看专业书籍了。这里我们用到的只是rtmp和hls，实践后发现：rtmp只能够在电脑端播放，hls只能够在手机端播放。而且rtmp是相当快的尽管没有rtsp那么快，延迟只有几秒，我测试的就差不多2-5秒，但是hls大概有10几秒。所以如果你体验过demo,就会发现手机延迟比较多。 直播的流程:直播分为推流和拉流两个过程，那么流推向哪里，拉流又从哪里拉取呢？那当然需要视频服务器啦，千万不要以为视频直播服务器很复杂，其实在nginx服务器中一切都变得简单。后面我会讲解如何部署Nginx服务器并配置视频模块(nginx-rtmp-module). 首先主播通过推流软件，比如OBS Studio推流软件，这个是比较专业级别的，很多直播平台的推荐主播使用这个软件来推送视频流，这里我也推荐一个开源的安卓端推流工具Yasea,下载地址，文件很小，但是很强大。直播内容推送到服务器后，就可以在服务器端使用视频编码工具进行转码了，可以转换成各种高清，标清，超清的分辨率视频，也就是为什么我们在各个视频网站都可以选择视频清晰度。这里我们没有转码，只是通过前端视频播放器(video.js)来拉取视频.这样整个视频推流拉流过程就完成了。 聊天室 直播间里面的聊天室跟我们的群聊天差不多，只不过它变成了web端，web端的即时通信方案有很多，这里我们选择websocket协议来与服务端通信，websocket是基于http之上的传输协议，客户端向服务端发送http请求，并携带Upgrade:websocket升级头信息表示转换websocket协议，通过与服务端握手成功后就可以建立tcp通道，由此来传递消息，它与http最大的差别就是，服务端可以主动向客户端发送消息。 既然建立了消息通道，那我们就需要往通道里发消息，但是总得需要一个东西来管控消息该发给谁吧，要不然全乱套了，所以我们选择了消息中间件RabbitMQ.使用它来负责消息的路由去向。 理论知识都讲完啦，实操时间到!#移动客户端实操源码地址 ##工程结构 1234567891011|—— build 构建服务和webpack配置 |—— congfig 项目不同环境的配置|—— dist build生成生产目录|—— static 静态资源|—— package.json 项目配置文件|—— src 开发源代码目录 |—— api 通过axios导出的api目录 |—— components 页面和组件 |—— public 公有组件 |—— vuex 全局状态 |—— main.js 应用启动配置点 ##功能模块 拉取服务器的直播视频流(hls)并播放直播画面 与服务端创建websocket连接，收发聊天室消息 通过websocket获取消息并发送到弹幕 通过websocket实时更新在线用户 结合服务端获取访问历史记录 问题反馈模块 ##效果图 ##项目说明请参考源码 #服务端实操源码地址 由于个人比较喜欢接触新的东西，所以后端选择了springboot，前端选择了Vue.js年轻人嘛总得跟上潮流。SpringBoot实践过后发现真的太省心了，不用再理会各种配置文件，全自动化装配。这里贴一下pom.xml 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.hushangjie&lt;/groupId&gt; &lt;artifactId&gt;rtmp-demo&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;rtmp-demo&lt;/name&gt; &lt;description&gt;Demo project for Spring Boot&lt;/description&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.5.4.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-actuator-docs&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-jpa&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt; &lt;/dependency&gt;--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-thymeleaf&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--非严格模式解析HTML5--&gt; &lt;dependency&gt; &lt;groupId&gt;net.sourceforge.nekohtml&lt;/groupId&gt; &lt;artifactId&gt;nekohtml&lt;/artifactId&gt; &lt;version&gt;1.9.22&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;!-- 打包成war时可以移除嵌入式tomcat插件 --&gt; &lt;!--&lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;--&gt; &lt;/dependency&gt; &lt;!--&lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;javax.servlet-api&lt;/artifactId&gt; &lt;version&gt;3.1.0&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt;--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-websocket&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.webjars&lt;/groupId&gt; &lt;artifactId&gt;vue&lt;/artifactId&gt; &lt;version&gt;2.1.3&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;joda-time&lt;/groupId&gt; &lt;artifactId&gt;joda-time&lt;/artifactId&gt; &lt;version&gt;2.9.2&lt;/version&gt; &lt;/dependency&gt; &lt;!-- RabbitMQ相关配置--&gt; &lt;dependency&gt; &lt;groupId&gt;io.projectreactor&lt;/groupId&gt; &lt;artifactId&gt;reactor-core&lt;/artifactId&gt; &lt;version&gt;2.0.8.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.projectreactor&lt;/groupId&gt; &lt;artifactId&gt;reactor-net&lt;/artifactId&gt; &lt;version&gt;2.0.8.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.netty&lt;/groupId&gt; &lt;artifactId&gt;netty-all&lt;/artifactId&gt; &lt;version&gt;4.1.6.Final&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;fork&gt;true&lt;/fork&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; application.properties文件 12345678910111213141516171819202122232425spring.datasource.url=jdbc:mysql://host:3306/database?characterEncoding=utf8&amp;amp;useSSL=falsespring.datasource.username=usernamespring.datasource.password=passwordspring.datasource.driver-class-name=com.mysql.jdbc.Driverspring.thymeleaf.mode=LEGACYHTML5server.port=8085# REDIS (RedisProperties)# Redis数据库索引（默认为0）spring.redis.database=0 # Redis服务器地址spring.redis.host=127.0.0.1# Redis服务器连接端口spring.redis.port=6379 # Redis服务器连接密码（默认为空）spring.redis.password=# 连接池最大连接数（使用负值表示没有限制）spring.redis.pool.max-active=8 # 连接池最大阻塞等待时间（使用负值表示没有限制）spring.redis.pool.max-wait=-1 # 连接池中的最大空闲连接spring.redis.pool.max-idle=8 # 连接池中的最小空闲连接spring.redis.pool.min-idle=0 # 连接超时时间（毫秒）spring.redis.timeout=0 ##websocket配置 1234567891011121314151617181920212223242526272829303132333435363738394041424344@Configuration@EnableWebSocketMessageBrokerpublic class WebSocketConfig extends AbstractWebSocketMessageBrokerConfigurer &#123; //拦截器注入service失败解决办法 @Bean public MyChannelInterceptor myChannelInterceptor()&#123; return new MyChannelInterceptor(); &#125; @Override public void registerStompEndpoints(StompEndpointRegistry registry) &#123; //添加访问域名限制可以防止跨域socket连接 //setAllowedOrigins(&quot;http://localhost:8085&quot;) registry.addEndpoint(&quot;/live&quot;).setAllowedOrigins(&quot;*&quot;).addInterceptors(new HandShkeInceptor()).withSockJS(); &#125; @Override public void configureMessageBroker(MessageBrokerRegistry registry) &#123; /*.enableSimpleBroker(&quot;/topic&quot;,&quot;/queue&quot;);*/ //假如需要第三方消息代理，比如rabitMQ,activeMq，在这里配置 registry.setApplicationDestinationPrefixes(&quot;/demo&quot;) .enableStompBrokerRelay(&quot;/topic&quot;,&quot;/queue&quot;) .setRelayHost(&quot;127.0.0.1&quot;) .setRelayPort(61613) .setClientLogin(&quot;guest&quot;) .setClientPasscode(&quot;guest&quot;) .setSystemLogin(&quot;guest&quot;) .setSystemPasscode(&quot;guest&quot;) .setSystemHeartbeatSendInterval(5000) .setSystemHeartbeatReceiveInterval(4000); &#125; @Override public void configureClientInboundChannel(ChannelRegistration registration) &#123; ChannelRegistration channelRegistration = registration.setInterceptors(myChannelInterceptor()); super.configureClientInboundChannel(registration); &#125; @Override public void configureClientOutboundChannel(ChannelRegistration registration) &#123; super.configureClientOutboundChannel(registration); &#125;&#125; 配置类继承了消息代理配置类，意味着我们将使用消息代理rabbitmq.使用registerStompEndpoints方法注册一个websocket终端连接。这里我们需要了解两个东西，第一个是stomp和sockjs,sockjs是啥呢，其实它是对于websocket的封装，因为如果单纯使用websocket的话效率会非常低，我们需要的编码量也会增多，而且如果浏览器不支持websocket，sockjs会自动降级为轮询策略，并模拟websocket,保证客户端和服务端可以通信。stomp有是什么看这里 stomp是一种简单(流)文本定向消息协议，它提供了一个可互操作的连接格式，允许STOMP客户端与任意STOMP消息代理（Broker）进行交互，也就是我们上面的RabbbitMQ,它就是一个消息代理。我们可以通过configureMessageBroker来配置消息代理，需要注意的是我们将要部署的服务器也应该要有RabbitMQ，因为它是一个中间件，安装非常容易，这里就不说明了。这里我们配置了“/topic,/queue”两个代理转播策略，就是说客户端订阅了前缀为“/topic,/queue”频道都会通过消息代理(RabbitMQ)来转发。跟spring没啥关系啦，完全解耦。 ##websocke如何保证安全 一开始接触 stomp的时候一直有个问题困扰我，客户端只要与服务端通过websocket建立了连接，那么他就可以订阅任何内容，意味着可以接受任何消息，这样岂不是乱了套啦，于是我翻阅了大量博客文章，很多都是官方的例子并没有解决实际问题。经过琢磨，其实websocket是要考虑安全性的。具体在以下几个方面 跨域websocket连接 协议升级前握手拦截器 消息信道拦截器 对于跨域问题，我们可以通过setAllowedOrigins方法来设置可连接的域名，防止跨站连接。 对于站内用户是否允许连接我们可以如下配置 12345678910111213141516171819202122232425262728293031323334public class HandShkeInceptor extends HttpSessionHandshakeInterceptor &#123; private static final Set&lt;UserEntity&gt; ONLINE_USERS = new HashSet&lt;&gt;(); @Override public boolean beforeHandshake(ServerHttpRequest request, ServerHttpResponse response, WebSocketHandler wsHandler, Map&lt;String, Object&gt; attributes) throws Exception &#123; System.out.println(&quot;握手前&quot;+request.getURI()); //http协议转换websoket协议进行前，通常这个拦截器可以用来判断用户合法性等 //鉴别用户 if (request instanceof ServletServerHttpRequest) &#123; ServletServerHttpRequest servletRequest = (ServletServerHttpRequest) request; //这句话很重要如果getSession(true)会导致移动端无法握手成功 //request.getSession(true)：若存在会话则返回该会话，否则新建一个会话。 //request.getSession(false)：若存在会话则返回该会话，否则返回NULL //HttpSession session = servletRequest.getServletRequest().getSession(false); HttpSession session = servletRequest.getServletRequest().getSession(); UserEntity user = (UserEntity) session.getAttribute(&quot;user&quot;); if (user != null) &#123; //这里只使用简单的session来存储用户，如果使用了springsecurity可以直接使用principal return super.beforeHandshake(request, response, wsHandler, attributes); &#125;else &#123; System.out.println(&quot;用户未登录，握手失败！&quot;); return false; &#125; &#125; return false; &#125; @Override public void afterHandshake(ServerHttpRequest request, ServerHttpResponse response, WebSocketHandler wsHandler, Exception ex) &#123; //握手成功后，通常用来注册用户信息 System.out.println(&quot;握手后&quot;); super.afterHandshake(request, response, wsHandler, ex); &#125;&#125; HttpSessionHandshakeInterceptor 这个拦截器用来管理握手和握手后的事情，我们可以通过请求信息，比如token、或者session判用户是否可以连接，这样就能够防范非法用户。 那如何限制用户只能订阅指定内容呢？我们接着往下看 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071public class MyChannelInterceptor extends ChannelInterceptorAdapter &#123; @Autowired private StatDao statDao; @Autowired private SimpMessagingTemplate simpMessagingTemplate; @Override public boolean preReceive(MessageChannel channel) &#123; System.out.println(&quot;preReceive&quot;); return super.preReceive(channel); &#125; @Override public Message&lt;?&gt; preSend(Message&lt;?&gt; message, MessageChannel channel) &#123; StompHeaderAccessor accessor = StompHeaderAccessor.wrap(message); StompCommand command = accessor.getCommand(); //检测用户订阅内容（防止用户订阅不合法频道） if (StompCommand.SUBSCRIBE.equals(command)) &#123; //从数据库获取用户订阅频道进行对比(这里为了演示直接使用set集合代替) Set&lt;String&gt; subedChannelInDB = new HashSet&lt;&gt;(); subedChannelInDB.add(&quot;/topic/group&quot;); subedChannelInDB.add(&quot;/topic/online_user&quot;); if (subedChannelInDB.contains(accessor.getDestination())) &#123; //该用户订阅的频道合法 return super.preSend(message, channel); &#125; else &#123; //该用户订阅的频道不合法直接返回null前端用户就接受不到该频道信息。 return null; &#125; &#125; else &#123; return super.preSend(message, channel); &#125; &#125; @Override public void afterSendCompletion(Message&lt;?&gt; message, MessageChannel channel, boolean sent, Exception ex) &#123; //System.out.println(&quot;afterSendCompletion&quot;); //检测用户是否连接成功，搜集在线的用户信息如果数据量过大我们可以选择使用缓存数据库比如redis, //这里由于需要频繁的删除和增加集合内容，我们选择set集合来存储在线用户 StompHeaderAccessor accessor = StompHeaderAccessor.wrap(message); StompCommand command = accessor.getCommand(); if (StompCommand.SUBSCRIBE.equals(command))&#123; Map&lt;String,UserEntity&gt; map = (Map&lt;String, UserEntity&gt;) accessor.getHeader(&quot;simpSessionAttributes&quot;); //ONLINE_USERS.add(map.get(&quot;user&quot;)); UserEntity user = map.get(&quot;user&quot;); if(user != null)&#123; statDao.pushOnlineUser(user); Guest guest = new Guest(); guest.setUserEntity(user); guest.setAccessTime(Calendar.getInstance().getTimeInMillis()); statDao.pushGuestHistory(guest); //通过websocket实时返回在线人数 this.simpMessagingTemplate.convertAndSend(&quot;/topic/online_user&quot;,statDao.getAllUserOnline()); &#125; &#125; //如果用户断开连接，删除用户信息 if (StompCommand.DISCONNECT.equals(command))&#123; Map&lt;String,UserEntity&gt; map = (Map&lt;String, UserEntity&gt;) accessor.getHeader(&quot;simpSessionAttributes&quot;); //ONLINE_USERS.remove(map.get(&quot;user&quot;)); UserEntity user = map.get(&quot;user&quot;); if (user != null)&#123; statDao.popOnlineUser(user); simpMessagingTemplate.convertAndSend(&quot;/topic/online_user&quot;,statDao.getAllUserOnline()); &#125; &#125; super.afterSendCompletion(message, channel, sent, ex); &#125;&#125; 在stomp里面，Channel信道就是消息传送的通道，客户端与服务端建立了连接就相当于建立了通道，以后的信息就是通过这个通道来传输。所有的消息都有消息头，被封装在了spring 的messag接口中，比如建立连接时候消息头就含有CONNECT,当然还有一些其他的信息。客户端订阅的时候也有订阅头信息SUBSCRIBE，那么我是不是可以在这个拦截器ChannelInterceptorAdapter 中拦截每个人的订阅信息，然后与数据库的信息作比对，最后决定这个用户是否可以订阅这个频道的信息呢，对的，这是我的想法，按照这样的思路，做单聊不是迎刃而解了吗。那客户端通过websocket发送的消息如何到达订阅者手中呢，按照rabbitmq的规则，订阅者属于消费者，发送消息的一方属于生产者，生产者通过websocket把消息发送到服务端，服务端通过转发给消息代理（rabbitmq）,消息代理负责存储消息，管理发送规则，推送消息给订阅者，看下面的代码 1234567891011@MessageMapping(value = &quot;/chat&quot;)@SendTo(&quot;/topic/group&quot;)public MsgEntity testWst(String message , @Header(value = &quot;simpSessionAttributes&quot;) Map&lt;String,Object&gt; session)&#123; UserEntity user = (UserEntity) session.get(&quot;user&quot;); String username = user.getRandomName(); MsgEntity msg = new MsgEntity(); msg.setCreator(username); msg.setsTime(Calendar.getInstance()); msg.setMsgBody(message); return msg;&#125; @MessageMapping看起来跟springmvc方法特别像，它即可以用在类级别上也可以用在方法级别上当发送者往‘/chat’发送消息后，服务端接受到消息，再发送给“/topic/group”的订阅者，@SendTo就是发送给谁，这里需要注意的有，如果我们没有配置消息代理，只使用了enableSimpleBroker(“/topic”,”/queue”)简单消息代理，那么就是直接发送到消息订阅者，如果配置了消息代理，那还要通过消息代理，由它来转发。 如果我们想在服务端随时发送消息，而不是在客户端发送（这样的场景很常见，比如发送全局通知），可以使用SimpMessagingTemplate类，通过注入该bean,在合适的业务场景中发送消息。 Redis统计数据直播间经常需要统计数据，比如实时在线人数，访问量，贡献排行榜，订阅量。我选择的方案是使用redis来计数，尽管这个demo可能不会太多人访问，但是我的目的是学习如何使用redis先看springboot中redis的配置 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061@Configurationpublic class RedisConfig extends CachingConfigurerSupport&#123; /** * 生成key的策略 * * @return */ @Bean public KeyGenerator keyGenerator() &#123; return new KeyGenerator() &#123; @Override public Object generate(Object target, Method method, Object... params) &#123; StringBuilder sb = new StringBuilder(); sb.append(target.getClass().getName()); sb.append(method.getName()); for (Object obj : params) &#123; sb.append(obj.toString()); &#125; return sb.toString(); &#125; &#125;; &#125; /** * 管理缓存 * * @param redisTemplate * @return */ @SuppressWarnings(&quot;rawtypes&quot;) @Bean public CacheManager cacheManager(RedisTemplate redisTemplate) &#123; RedisCacheManager rcm = new RedisCacheManager(redisTemplate); //设置缓存过期时间 // rcm.setDefaultExpiration(60);//秒 //设置value的过期时间 Map&lt;String,Long&gt; map=new HashMap(); map.put(&quot;test&quot;,60L); rcm.setExpires(map); return rcm; &#125; /** * RedisTemplate配置 * @param factory * @return */ @Bean public RedisTemplate&lt;String, String&gt; redisTemplate(RedisConnectionFactory factory) &#123; StringRedisTemplate template = new StringRedisTemplate(factory); Jackson2JsonRedisSerializer jackson2JsonRedisSerializer = new Jackson2JsonRedisSerializer(Object.class); ObjectMapper om = new ObjectMapper(); om.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY); om.enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL); jackson2JsonRedisSerializer.setObjectMapper(om); template.setValueSerializer(jackson2JsonRedisSerializer);//如果key是String 需要配置一下StringSerializer,不然key会乱码 /XX/XX template.afterPropertiesSet(); //template.setStringSerializer(); return template; &#125;&#125; redis数据统计Dao的实现 123456789101112131415161718192021222324@Repositorypublic class StatDao &#123; @Autowired RedisTemplate redisTemplate; public void pushOnlineUser(UserEntity userEntity)&#123; redisTemplate.opsForSet().add(&quot;OnlineUser&quot;,userEntity); &#125; public void popOnlineUser(UserEntity userEntity)&#123; redisTemplate.opsForSet().remove(&quot;OnlineUser&quot; ,userEntity); &#125; public Set getAllUserOnline()&#123; return redisTemplate.opsForSet().members(&quot;OnlineUser&quot;); &#125; public void pushGuestHistory(Guest guest)&#123; //最多存储指定个数的访客 if (redisTemplate.opsForList().size(&quot;Guest&quot;) == 200l)&#123; redisTemplate.opsForList().rightPop(&quot;Guest&quot;); &#125; redisTemplate.opsForList().leftPush(&quot;Guest&quot;,guest); &#125; public List getGuestHistory()&#123; return redisTemplate.opsForList().range(&quot;Guest&quot;,0,-1); &#125;&#125; Dao层非常简单，因为我们只需要统计在线人数和访客。但是在线人数是实时更新的，既然我们使用了websocket实时数据更新就非常容易了，前面我们讲过，通过信道拦截器可以拦截连接，订阅，断开连接等等事件信息，所以我们就可以当用户连接时存储在线用户，通过websocket返回在线用户信息。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071public class MyChannelInterceptor extends ChannelInterceptorAdapter &#123; @Autowired private StatDao statDao; @Autowired private SimpMessagingTemplate simpMessagingTemplate; @Override public boolean preReceive(MessageChannel channel) &#123; System.out.println(&quot;preReceive&quot;); return super.preReceive(channel); &#125; @Override public Message&lt;?&gt; preSend(Message&lt;?&gt; message, MessageChannel channel) &#123; StompHeaderAccessor accessor = StompHeaderAccessor.wrap(message); StompCommand command = accessor.getCommand(); //检测用户订阅内容（防止用户订阅不合法频道） if (StompCommand.SUBSCRIBE.equals(command)) &#123; //从数据库获取用户订阅频道进行对比(这里为了演示直接使用set集合代替) Set&lt;String&gt; subedChannelInDB = new HashSet&lt;&gt;(); subedChannelInDB.add(&quot;/topic/group&quot;); subedChannelInDB.add(&quot;/topic/online_user&quot;); if (subedChannelInDB.contains(accessor.getDestination())) &#123; //该用户订阅的频道合法 return super.preSend(message, channel); &#125; else &#123; //该用户订阅的频道不合法直接返回null前端用户就接受不到该频道信息。 return null; &#125; &#125; else &#123; return super.preSend(message, channel); &#125; &#125; @Override public void afterSendCompletion(Message&lt;?&gt; message, MessageChannel channel, boolean sent, Exception ex) &#123; //System.out.println(&quot;afterSendCompletion&quot;); //检测用户是否连接成功，搜集在线的用户信息如果数据量过大我们可以选择使用缓存数据库比如redis, //这里由于需要频繁的删除和增加集合内容，我们选择set集合来存储在线用户 StompHeaderAccessor accessor = StompHeaderAccessor.wrap(message); StompCommand command = accessor.getCommand(); if (StompCommand.SUBSCRIBE.equals(command))&#123; Map&lt;String,UserEntity&gt; map = (Map&lt;String, UserEntity&gt;) accessor.getHeader(&quot;simpSessionAttributes&quot;); //ONLINE_USERS.add(map.get(&quot;user&quot;)); UserEntity user = map.get(&quot;user&quot;); if(user != null)&#123; statDao.pushOnlineUser(user); Guest guest = new Guest(); guest.setUserEntity(user); guest.setAccessTime(Calendar.getInstance().getTimeInMillis()); statDao.pushGuestHistory(guest); //通过websocket实时返回在线人数 this.simpMessagingTemplate.convertAndSend(&quot;/topic/online_user&quot;,statDao.getAllUserOnline()); &#125; &#125; //如果用户断开连接，删除用户信息 if (StompCommand.DISCONNECT.equals(command))&#123; Map&lt;String,UserEntity&gt; map = (Map&lt;String, UserEntity&gt;) accessor.getHeader(&quot;simpSessionAttributes&quot;); //ONLINE_USERS.remove(map.get(&quot;user&quot;)); UserEntity user = map.get(&quot;user&quot;); if (user != null)&#123; statDao.popOnlineUser(user); simpMessagingTemplate.convertAndSend(&quot;/topic/online_user&quot;,statDao.getAllUserOnline()); &#125; &#125; super.afterSendCompletion(message, channel, sent, ex); &#125;&#125; 由于这个项目有移动端和电脑端，所以需要根据请求代理UserAgent来判断客户端属于哪一种类型。这个工具类在源码上有。我就不贴了。 #服务器部署说了这么多即时通信，却没发现视频直播。不要着急我们马上进入视频环节。文章开头就说明了几种媒体流协议，这里不讲解详细的协议流程，只需要知道，我们是通过推流软件采集视频信息，如何采集也不是我们关注的。采集到信息后通过软件来推送到指定的服务器，如下图 obs推流设置yasea手机端推流设置 红色部分是服务器开放的获取流接口。 ##Nginx-rtmp-module配置视频服务器有很多，也支持很多媒体流协议。这里我们选择nginx-rtmp-module来做视频服务，接下来我们需要在linux下安装nginx,并安装rtmp模块。本人也是linux初学者，一步步摸索着把服务器搭建好，听说tomcat和nginx很配哦，所以作为免费开源的当然首选这两个。接下来需要在linux安装一下软件和服务。 Nginx以及Nginx-rtmp-module Tomcat Mysql Redis RabbitMQ 安装步骤我就不说了，大家搜索一下啦，这里贴一下nginx.conf文件配置 12345678910111213141516rtmp &#123; server &#123; listen 1935; chunk_size 4096; application video &#123; play /yjdata/www/www/video; &#125; application live &#123; live on; hls on; hls_path /yjdata/www/www/live/hls/; hls_fragment 5s; &#125; &#125;&#125; 上面代码是配置rtmp模块, play /yjdata/www/www/video 指的是配置点播模块，可以直接播放/yjdata/www/www/video路径下的视频。hls_path制定hls分块存放路径，因为hls是通过获取到推送的视频流信息，分块存储在服务器。所以它的延时比rtmp要更高。1234567891011121314151617181920212223242526272829303132333435server &#123; listen 80; server_name localhost; #charset koi8-r; index index.jsp index.html; root /yjdata/www/www; #access_log logs/host.access.log main; location / &#123; proxy_pass http://127.0.0.1:8080; &#125; location ~ .*\\.(gif|jpg|jpeg|png|bmp|swf|js|css|docx|pdf|doc|ppt|html|properties)$ &#123; expires 30d; root /yjdata/www/www/static/; &#125; location /hls &#123; types &#123; application/vnd.apple.mpegurl m3u8; #application/x-mpegURL; video/mp2t ts; &#125; alias /yjdata/www/www/live/hls/; expires -1; add_header Cache-Control no-cache; &#125; location /stat &#123; rtmp_stat all; rtmp_stat_stylesheet stat.xsl; &#125; location /stat.xsl &#123; root /soft/nginx/nginx-rtmp-module/; &#125; 上面配置了location 指向/hls,别名是/yjdata/www/www/live/hls/，所以可以在前端直接通过域名+/hls/+文件名.m3u8获取直播视频。关于nginx的配置还有很多，我也在学习当中。总而言之nginx非常强大。 #总结通过从前端=&gt;后台=&gt;服务器，整个流程走下来还是需要花很多心思。但是收获也是很多。本人将从大学出来，初出茅庐,文章错误之处，尽请指正。本人邮箱979783618@qq.com[1]: /img/bVPDP5 [2]: /img/bVPDQd [3]: /img/bVPDYu [4]: /img/bVPDZo [5]: /img/bVPDZ1","categories":[{"name":"项目实战","slug":"项目实战","permalink":"http://blog.jackhoo.cn/categories/项目实战/"}],"tags":[{"name":"vue","slug":"vue","permalink":"http://blog.jackhoo.cn/tags/vue/"},{"name":"直播","slug":"直播","permalink":"http://blog.jackhoo.cn/tags/直播/"}]}]}